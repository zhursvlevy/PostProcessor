{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGradient boosting with trees for topic classification\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "module_path = os.path.abspath(os.path.join('..\\..')) # Path to root folder\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path + \"/scripts\") # define scripts path\n",
    "\n",
    "from ipynb_func import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data loader:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NUM = 10 # Number of data parquets to use\n",
    "#assert NUM >= 1 and NUM <= 10, \"NUM value must be in range [1, 10]\"\n",
    "\n",
    "# Making list of roots to merge processed raw data \n",
    "#paths = [module_path + f\"/data/pikabu/tag_processed/raw_data/{i}_tag_processed.parquet\" for i in range(NUM)] \n",
    "\n",
    "# Making list of roots to merge processed filtered data\n",
    "#paths = [module_path + f\"/data/pikabu/tag_processed/filtered_data/{i}_tag_processed.parquet\" for i in range(NUM)] \n",
    "\n",
    "# Making list of roots to merge processed cleared data\n",
    "paths = [module_path + f\"/data/pikabu/splited_data/cleared_texts.parquet\"] \n",
    "\n",
    "data = merge_dataset(paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text_markdown</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>6991359</td>\n",
       "      <td>[добрый, сутки, господин, дама, подсказывать, название, игра, телефон, оформление, убийство, зомби, очки, ездить, машинка, кру...</td>\n",
       "      <td>[игры, поиск]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>7004423</td>\n",
       "      <td>[ехать, девчонка, школа, оставаться, свободный, макс, заявка, прямой, конечный, адрес, железнодорожный, институт, включать, вб...</td>\n",
       "      <td>[юмор]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>6991603</td>\n",
       "      <td>[стадо, стадо, гигантский, случаться, стадо, управлять, волк, предел, волк, жопа, враг, дружно, осматривать, выдавливать, стад...</td>\n",
       "      <td>[мат]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  \\\n",
       "15  6991359   \n",
       "37  7004423   \n",
       "52  6991603   \n",
       "\n",
       "                                                                                                                        text_markdown  \\\n",
       "15  [добрый, сутки, господин, дама, подсказывать, название, игра, телефон, оформление, убийство, зомби, очки, ездить, машинка, кру...   \n",
       "37  [ехать, девчонка, школа, оставаться, свободный, макс, заявка, прямой, конечный, адрес, железнодорожный, институт, включать, вб...   \n",
       "52  [стадо, стадо, гигантский, случаться, стадо, управлять, волк, предел, волк, жопа, враг, дружно, осматривать, выдавливать, стад...   \n",
       "\n",
       "             tags  \n",
       "15  [игры, поиск]  \n",
       "37         [юмор]  \n",
       "52          [мат]  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', 130)\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 1. Data preparation and split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(module_path + f\"/data/pikabu/splited_data/indexes.json\") as f:\n",
    "    id_splits = f.read()\n",
    "\n",
    "id_splits = json.loads(id_splits)\n",
    "\n",
    "data_train = data[data['id'].isin(id_splits['train'])]\n",
    "data_val = data[data['id'].isin(id_splits['val'])]\n",
    "data_test = data[data['id'].isin(id_splits['test'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train data: 25209\n",
      "Number of val data: 2821\n",
      "Number of test data: 3119\n",
      "Distribution: 81 / 9 / 10\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of train data: {len(data_train)}\")\n",
    "print(f\"Number of val data: {len(data_val)}\")\n",
    "print(f\"Number of test data: {len(data_test)}\")\n",
    "print(f\"Distribution: {len(data_train)/len(data)*100:.0f} / {len(data_val)/len(data)*100:.0f} / {len(data_test)/len(data)*100:.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 2. Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "import xgboost as xgb\n",
    "from joblib import dump, load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Target preparation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\decique\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "Vec = CountVectorizer(tokenizer=lambda x: x.split(','), binary=True)\n",
    "\n",
    "df = data.copy()\n",
    "df.tags = [','.join(i) for i in df.tags]\n",
    "\n",
    "df_train = data_train.copy()\n",
    "df_train.tags = [','.join(i) for i in df_train.tags]\n",
    "\n",
    "df_val = data_val.copy()\n",
    "df_val.tags = [','.join(i) for i in df_val.tags]\n",
    "\n",
    "df_test = data_test.copy()\n",
    "df_test.tags = [','.join(i) for i in df_test.tags]\n",
    "\n",
    "y_data = Vec.fit(df['tags'])\n",
    "y_train = Vec.transform(df_train['tags'])\n",
    "y_val = Vec.transform(df_val['tags'])\n",
    "y_test = Vec.transform(df_test['tags'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tags to predict:\n",
      "['авто' 'авторский рассказ' 'алкоголь' 'анекдот' 'армия' 'вопрос' 'врачи'\n",
      " 'девушки' 'деньги' 'дети' 'детство' 'другое' 'жизнь' 'игры' 'интересное'\n",
      " 'истории' 'история' 'ищу книгу' 'ищу фильм' 'карантин' 'книги'\n",
      " 'коронавирус' 'кот' 'лига добра' 'лига юристов' 'любовь' 'люди' 'мат'\n",
      " 'медицина' 'москва' 'музыка' 'мысли' 'негатив' 'новости' 'новый год'\n",
      " 'общество' 'отношения' 'поиск' 'политика' 'помогите найти' 'помощь'\n",
      " 'психология' 'работа' 'рассказ' 'реальная история из жизни'\n",
      " 'родители и дети' 'россия' 'самоизоляция' 'санкт-петербург' 'семья'\n",
      " 'случай из жизни' 'совет' 'сон' 'соседи' 'стихи' 'украина' 'фантастика'\n",
      " 'фильмы' 'школа' 'юмор']\n"
     ]
    }
   ],
   "source": [
    "print('Tags to predict:')\n",
    "print(Vec.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_distr = getworddict(getwordlist(data.tags))\n",
    "tag_distr_formated = {}\n",
    "for i in range(len(tag_distr)):\n",
    "    tag_distr_formated[i] = round(tag_distr[Vec.get_feature_names_out()[i]] / sum(tag_distr.values()), 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tags weights:\n",
      "{0: 0.0073, 1: 0.0121, 2: 0.0075, 3: 0.0079, 4: 0.0085, 5: 0.0196, 6: 0.0077, 7: 0.0138, 8: 0.0089, 9: 0.0279, 10: 0.011, 11: 0.0221, 12: 0.0186, 13: 0.0122, 14: 0.0122, 15: 0.0086, 16: 0.0338, 17: 0.0067, 18: 0.008, 19: 0.014, 20: 0.0107, 21: 0.0454, 22: 0.0121, 23: 0.0142, 24: 0.0078, 25: 0.0149, 26: 0.0084, 27: 0.0549, 28: 0.0125, 29: 0.0098, 30: 0.0081, 31: 0.0093, 32: 0.0145, 33: 0.0152, 34: 0.0133, 35: 0.0237, 36: 0.0206, 37: 0.0071, 38: 0.0308, 39: 0.0118, 40: 0.054, 41: 0.0121, 42: 0.0297, 43: 0.0303, 44: 0.0315, 45: 0.0082, 46: 0.0277, 47: 0.0063, 48: 0.0075, 49: 0.0145, 50: 0.0122, 51: 0.0078, 52: 0.0067, 53: 0.0086, 54: 0.0274, 55: 0.0275, 56: 0.0111, 57: 0.0104, 58: 0.0144, 59: 0.0384}\n"
     ]
    }
   ],
   "source": [
    "print('Tags weights:')\n",
    "print(tag_distr_formated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y shapes:\n",
      "  • Y train: (25209, 60)\n",
      "  • Y validation: (2821, 60)\n",
      "  • Y test: (3119, 60)\n"
     ]
    }
   ],
   "source": [
    "print('Y shapes:')\n",
    "print(f'  • Y train: {y_train.shape}')\n",
    "print(f'  • Y validation: {y_val.shape}')\n",
    "print(f'  • Y test: {y_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Training with bag-of-words embeddings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_models_path = module_path + '/models/xgb/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data = [' '.join(txt) for txt in data.text_markdown]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = [' '.join(txt) for txt in data_train.text_markdown]\n",
    "X_val = [' '.join(txt) for txt in data_val.text_markdown]\n",
    "X_test = [' '.join(txt) for txt in data_test.text_markdown]\n",
    "\n",
    "X_Vec = CountVectorizer(tokenizer = lambda x: x.split())\n",
    "\n",
    "X_Vec.fit(X_train)\n",
    "X_train = X_Vec.transform(X_train)\n",
    "X_test = X_Vec.transform(X_test)\n",
    "X_val = X_Vec.transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X BoW's shapes:\n",
      "   • X train shape: (25209, 5899)\n",
      "   • X val shape: (2821, 5899)\n",
      "   • X test shape: (3119, 5899)\n"
     ]
    }
   ],
   "source": [
    "print(\"X BoW's shapes:\")\n",
    "print(f'   • X train shape: {X_train.shape}')\n",
    "print(f'   • X val shape: {X_val.shape}')\n",
    "print(f'   • X test shape: {X_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" # Searching for best model params; too long;\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "cfg = {'estimator__n_estimators': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "       'estimator__max_depth': [2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "       'estimator__learning_rate': [1, 10, 100, 1000, 1e5]}\n",
    "\n",
    "clf_ovr = OneVsRestClassifier(estimator=xgb.XGBClassifier(n_estimators=5,\n",
    "                                                          max_depth=5,\n",
    "                                                          learning_rate=10,\n",
    "                                                          objective='binary:logistic',\n",
    "                                                          random_state=42),\n",
    "                              n_jobs=-1)\n",
    "\n",
    "GSCV_clf = GridSearchCV(estimator=clf_ovr, param_grid=cfg, n_jobs=-1)\n",
    "\n",
    "GSCV_clf.fit(X_train, y_train)\n",
    "\n",
    "GSCV_params = GSCV_clf.best_params_  \"\"\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_ovr = OneVsRestClassifier(estimator=xgb.XGBClassifier(tree_method='auto',\n",
    "                                                          n_estimators=1,\n",
    "                                                          max_depth=25,\n",
    "                                                          learning_rate=1e5,\n",
    "                                                          objective='binary:logistic',\n",
    "                                                          random_state=42),\n",
    "                              n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isfile(save_models_path + 'bow.joblib'):\n",
    "    clf_ovr = load(save_models_path + 'bow.joblib')\n",
    "else:\n",
    "    clf_ovr.fit(X_train, y_train)\n",
    "    dump(clf_ovr, save_models_path + 'bow.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_y_pred_val = clf_ovr.predict(X_val)\n",
    "bow_y_probas = clf_ovr.predict_proba(X_val)\n",
    "bow_y_labels = sorted_labels(bow_y_pred_val, bow_y_probas, Vec)\n",
    "\n",
    "bow_df_val = data_val.copy()\n",
    "bow_df_val['predicted_tags'] = bow_y_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text_markdown</th>\n",
       "      <th>tags</th>\n",
       "      <th>predicted_tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>421</th>\n",
       "      <td>6992880</td>\n",
       "      <td>[популярный, пк, игра, создавать, устройство, проходить, картинка, память, оставаться, различный, создавать, написать, догадка...</td>\n",
       "      <td>[помогите найти]</td>\n",
       "      <td>[интересное]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432</th>\n",
       "      <td>6992917</td>\n",
       "      <td>[профессия, оказываться, сопровождать, образование, курсы, обязанность, входить, хотеться, разговор, зажигать, свеча, оказыват...</td>\n",
       "      <td>[психология]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>578</th>\n",
       "      <td>6994231</td>\n",
       "      <td>[предыдущий, пост, бригада, график, переписывать, месяц, дата, окончание, поездка, графика, случаться, называть, двойной, поез...</td>\n",
       "      <td>[юмор, реальная история из жизни]</td>\n",
       "      <td>[анекдот, любовь, работа]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>591</th>\n",
       "      <td>6992488</td>\n",
       "      <td>[широкий, хотеться, обращать, внимание, инцидент, связанный, дтп, участие, пожарный, двигаться, оперативный, вызов, включать, ...</td>\n",
       "      <td>[помощь]</td>\n",
       "      <td>[лига юристов, помощь]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>807</th>\n",
       "      <td>7021892</td>\n",
       "      <td>[история, скоро, девушка, упасть, дерево, парень, неловко, улыбаться, следовать, забывать, следить, окружение, темно, отзывать...</td>\n",
       "      <td>[рассказ, фантастика, мат]</td>\n",
       "      <td>[авторский рассказ, детство, игры, истории, любовь, люди, мысли, поиск, помощь, рассказ, родители и дети, фантастика, юмор]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  \\\n",
       "421  6992880   \n",
       "432  6992917   \n",
       "578  6994231   \n",
       "591  6992488   \n",
       "807  7021892   \n",
       "\n",
       "                                                                                                                         text_markdown  \\\n",
       "421  [популярный, пк, игра, создавать, устройство, проходить, картинка, память, оставаться, различный, создавать, написать, догадка...   \n",
       "432  [профессия, оказываться, сопровождать, образование, курсы, обязанность, входить, хотеться, разговор, зажигать, свеча, оказыват...   \n",
       "578  [предыдущий, пост, бригада, график, переписывать, месяц, дата, окончание, поездка, графика, случаться, называть, двойной, поез...   \n",
       "591  [широкий, хотеться, обращать, внимание, инцидент, связанный, дтп, участие, пожарный, двигаться, оперативный, вызов, включать, ...   \n",
       "807  [история, скоро, девушка, упасть, дерево, парень, неловко, улыбаться, следовать, забывать, следить, окружение, темно, отзывать...   \n",
       "\n",
       "                                  tags  \\\n",
       "421                   [помогите найти]   \n",
       "432                       [психология]   \n",
       "578  [юмор, реальная история из жизни]   \n",
       "591                           [помощь]   \n",
       "807         [рассказ, фантастика, мат]   \n",
       "\n",
       "                                                                                                                  predicted_tags  \n",
       "421                                                                                                                 [интересное]  \n",
       "432                                                                                                                           []  \n",
       "578                                                                                                    [анекдот, любовь, работа]  \n",
       "591                                                                                                       [лига юристов, помощь]  \n",
       "807  [авторский рассказ, детство, игры, истории, любовь, люди, мысли, поиск, помощь, рассказ, родители и дети, фантастика, юмор]  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_df_val.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for Bag-of-Words:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.16      0.52      0.25        25\n",
      "           1       0.15      0.36      0.21        45\n",
      "           2       0.20      0.38      0.26        40\n",
      "           3       0.09      0.15      0.11        27\n",
      "           4       0.19      0.56      0.28        27\n",
      "           5       0.05      0.12      0.07        68\n",
      "           6       0.23      0.38      0.29        40\n",
      "           7       0.16      0.41      0.23        59\n",
      "           8       0.10      0.19      0.13        42\n",
      "           9       0.18      0.46      0.26       113\n",
      "          10       0.11      0.26      0.15        50\n",
      "          11       0.02      0.01      0.01        85\n",
      "          12       0.07      0.10      0.08        72\n",
      "          13       0.40      0.81      0.54        58\n",
      "          14       0.05      0.06      0.06        52\n",
      "          15       0.01      0.04      0.02        28\n",
      "          16       0.09      0.11      0.10       135\n",
      "          17       0.11      0.35      0.17        23\n",
      "          18       0.23      0.72      0.34        25\n",
      "          19       0.25      0.56      0.35        50\n",
      "          20       0.14      0.38      0.21        29\n",
      "          21       0.58      0.79      0.67       164\n",
      "          22       0.38      0.76      0.51        45\n",
      "          23       0.21      0.27      0.24        77\n",
      "          24       0.28      0.50      0.36        32\n",
      "          25       0.08      0.23      0.11        47\n",
      "          26       0.00      0.00      0.00        25\n",
      "          27       0.62      0.72      0.66       218\n",
      "          28       0.19      0.58      0.28        48\n",
      "          29       0.13      0.31      0.18        39\n",
      "          30       0.20      0.53      0.29        38\n",
      "          31       0.03      0.08      0.05        38\n",
      "          32       0.12      0.21      0.15        53\n",
      "          33       0.16      0.40      0.23        57\n",
      "          34       0.28      0.54      0.37        57\n",
      "          35       0.05      0.07      0.06       102\n",
      "          36       0.21      0.41      0.28        90\n",
      "          37       0.03      0.09      0.04        23\n",
      "          38       0.28      0.52      0.37       136\n",
      "          39       0.09      0.22      0.13        45\n",
      "          40       0.29      0.49      0.36       243\n",
      "          41       0.15      0.37      0.21        49\n",
      "          42       0.21      0.42      0.28       113\n",
      "          43       0.24      0.41      0.30       133\n",
      "          44       0.09      0.21      0.13       118\n",
      "          45       0.08      0.26      0.12        31\n",
      "          46       0.19      0.31      0.24       105\n",
      "          47       0.18      0.31      0.23        29\n",
      "          48       0.24      0.55      0.33        29\n",
      "          49       0.12      0.24      0.16        68\n",
      "          50       0.01      0.02      0.02        47\n",
      "          51       0.05      0.14      0.07        22\n",
      "          52       0.17      0.36      0.23        36\n",
      "          53       0.24      0.69      0.36        29\n",
      "          54       0.28      0.46      0.35       116\n",
      "          55       0.46      0.84      0.59        99\n",
      "          56       0.28      0.46      0.34        46\n",
      "          57       0.31      0.66      0.42        38\n",
      "          58       0.30      0.64      0.41        53\n",
      "          59       0.12      0.14      0.13       160\n",
      "\n",
      "   micro avg       0.21      0.39      0.27      3991\n",
      "   macro avg       0.18      0.37      0.24      3991\n",
      "weighted avg       0.22      0.39      0.28      3991\n",
      " samples avg       0.23      0.39      0.26      3991\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Metrics for Bag-of-Words:')\n",
    "print(classification_report(y_val, bow_y_pred_val, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate `recall@k`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall@k for Bag-of-Words: 0.5487\n"
     ]
    }
   ],
   "source": [
    "bow_recallk = recallk(bow_df_val.tags, bow_df_val.predicted_tags, k=10)\n",
    "print(f'Recall@k for Bag-of-Words: {bow_recallk:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Training with IF-IDF embeddings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\decique\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "X_train = [' '.join(txt) for txt in data_train.text_markdown]\n",
    "X_val = [' '.join(txt) for txt in data_val.text_markdown]\n",
    "X_test = [' '.join(txt) for txt in data_test.text_markdown]\n",
    "\n",
    "Tfidf_Vec = TfidfVectorizer(tokenizer = lambda x: x.split())\n",
    "\n",
    "Tfidf_Vec.fit(X_train)\n",
    "X_train = Tfidf_Vec.transform(X_train)\n",
    "X_test = Tfidf_Vec.transform(X_test)\n",
    "X_val = Tfidf_Vec.transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X TF-IDF's shapes:\n",
      "   • X train shape: (25209, 5899)\n",
      "   • X val shape: (2821, 5899)\n",
      "   • X test shape: (3119, 5899)\n"
     ]
    }
   ],
   "source": [
    "print(\"X TF-IDF's shapes:\")\n",
    "print(f'   • X train shape: {X_train.shape}')\n",
    "print(f'   • X val shape: {X_val.shape}')\n",
    "print(f'   • X test shape: {X_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_ovr = OneVsRestClassifier(estimator=xgb.XGBClassifier(tree_method='auto',\n",
    "                                                          n_estimators=5,\n",
    "                                                          max_depth=15,\n",
    "                                                          learning_rate=1e5,\n",
    "                                                          objective='binary:logistic',\n",
    "                                                          random_state=42),\n",
    "                              n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isfile(save_models_path + 'tf_idf.joblib'):\n",
    "    clf_ovr = load(save_models_path + 'tf_idf.joblib')\n",
    "else:\n",
    "    clf_ovr.fit(X_train, y_train)\n",
    "    dump(clf_ovr, save_models_path + 'tf_idf.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_y_pred_val = clf_ovr.predict(X_val)\n",
    "tf_idf_y_probas = clf_ovr.predict_proba(X_val)\n",
    "tf_idf_y_labels = sorted_labels(tf_idf_y_pred_val, tf_idf_y_probas, Vec)\n",
    "\n",
    "tf_idf_df_val = data_val.copy()\n",
    "tf_idf_df_val['predicted_tags'] = tf_idf_y_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text_markdown</th>\n",
       "      <th>tags</th>\n",
       "      <th>predicted_tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>421</th>\n",
       "      <td>6992880</td>\n",
       "      <td>[популярный, пк, игра, создавать, устройство, проходить, картинка, память, оставаться, различный, создавать, написать, догадка...</td>\n",
       "      <td>[помогите найти]</td>\n",
       "      <td>[игры]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432</th>\n",
       "      <td>6992917</td>\n",
       "      <td>[профессия, оказываться, сопровождать, образование, курсы, обязанность, входить, хотеться, разговор, зажигать, свеча, оказыват...</td>\n",
       "      <td>[психология]</td>\n",
       "      <td>[психология, работа]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>578</th>\n",
       "      <td>6994231</td>\n",
       "      <td>[предыдущий, пост, бригада, график, переписывать, месяц, дата, окончание, поездка, графика, случаться, называть, двойной, поез...</td>\n",
       "      <td>[юмор, реальная история из жизни]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>591</th>\n",
       "      <td>6992488</td>\n",
       "      <td>[широкий, хотеться, обращать, внимание, инцидент, связанный, дтп, участие, пожарный, двигаться, оперативный, вызов, включать, ...</td>\n",
       "      <td>[помощь]</td>\n",
       "      <td>[вопрос, лига юристов]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>807</th>\n",
       "      <td>7021892</td>\n",
       "      <td>[история, скоро, девушка, упасть, дерево, парень, неловко, улыбаться, следовать, забывать, следить, окружение, темно, отзывать...</td>\n",
       "      <td>[рассказ, фантастика, мат]</td>\n",
       "      <td>[авторский рассказ, книги, рассказ]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  \\\n",
       "421  6992880   \n",
       "432  6992917   \n",
       "578  6994231   \n",
       "591  6992488   \n",
       "807  7021892   \n",
       "\n",
       "                                                                                                                         text_markdown  \\\n",
       "421  [популярный, пк, игра, создавать, устройство, проходить, картинка, память, оставаться, различный, создавать, написать, догадка...   \n",
       "432  [профессия, оказываться, сопровождать, образование, курсы, обязанность, входить, хотеться, разговор, зажигать, свеча, оказыват...   \n",
       "578  [предыдущий, пост, бригада, график, переписывать, месяц, дата, окончание, поездка, графика, случаться, называть, двойной, поез...   \n",
       "591  [широкий, хотеться, обращать, внимание, инцидент, связанный, дтп, участие, пожарный, двигаться, оперативный, вызов, включать, ...   \n",
       "807  [история, скоро, девушка, упасть, дерево, парень, неловко, улыбаться, следовать, забывать, следить, окружение, темно, отзывать...   \n",
       "\n",
       "                                  tags                       predicted_tags  \n",
       "421                   [помогите найти]                               [игры]  \n",
       "432                       [психология]                 [психология, работа]  \n",
       "578  [юмор, реальная история из жизни]                                   []  \n",
       "591                           [помощь]               [вопрос, лига юристов]  \n",
       "807         [рассказ, фантастика, мат]  [авторский рассказ, книги, рассказ]  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf_df_val.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for TF-IDF:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.16      0.40      0.23        25\n",
      "           1       0.20      0.36      0.26        45\n",
      "           2       0.25      0.40      0.31        40\n",
      "           3       0.20      0.22      0.21        27\n",
      "           4       0.29      0.56      0.38        27\n",
      "           5       0.12      0.18      0.15        68\n",
      "           6       0.27      0.42      0.33        40\n",
      "           7       0.18      0.36      0.24        59\n",
      "           8       0.12      0.17      0.14        42\n",
      "           9       0.25      0.37      0.30       113\n",
      "          10       0.13      0.22      0.16        50\n",
      "          11       0.06      0.04      0.05        85\n",
      "          12       0.09      0.07      0.08        72\n",
      "          13       0.42      0.78      0.54        58\n",
      "          14       0.03      0.02      0.02        52\n",
      "          15       0.02      0.04      0.03        28\n",
      "          16       0.11      0.09      0.10       135\n",
      "          17       0.22      0.57      0.31        23\n",
      "          18       0.28      0.60      0.38        25\n",
      "          19       0.27      0.46      0.34        50\n",
      "          20       0.14      0.31      0.19        29\n",
      "          21       0.66      0.73      0.69       164\n",
      "          22       0.40      0.73      0.52        45\n",
      "          23       0.29      0.38      0.33        77\n",
      "          24       0.37      0.41      0.39        32\n",
      "          25       0.11      0.28      0.16        47\n",
      "          26       0.00      0.00      0.00        25\n",
      "          27       0.70      0.67      0.69       218\n",
      "          28       0.17      0.27      0.21        48\n",
      "          29       0.21      0.31      0.25        39\n",
      "          30       0.28      0.71      0.40        38\n",
      "          31       0.11      0.13      0.12        38\n",
      "          32       0.16      0.23      0.19        53\n",
      "          33       0.18      0.25      0.21        57\n",
      "          34       0.38      0.67      0.48        57\n",
      "          35       0.12      0.06      0.08       102\n",
      "          36       0.21      0.30      0.24        90\n",
      "          37       0.10      0.22      0.13        23\n",
      "          38       0.36      0.49      0.42       136\n",
      "          39       0.15      0.31      0.20        45\n",
      "          40       0.39      0.46      0.42       243\n",
      "          41       0.19      0.33      0.24        49\n",
      "          42       0.32      0.41      0.36       113\n",
      "          43       0.28      0.35      0.32       133\n",
      "          44       0.11      0.19      0.14       118\n",
      "          45       0.09      0.32      0.14        31\n",
      "          46       0.18      0.23      0.20       105\n",
      "          47       0.24      0.38      0.30        29\n",
      "          48       0.23      0.34      0.28        29\n",
      "          49       0.16      0.26      0.20        68\n",
      "          50       0.03      0.04      0.03        47\n",
      "          51       0.07      0.14      0.09        22\n",
      "          52       0.33      0.47      0.39        36\n",
      "          53       0.21      0.55      0.30        29\n",
      "          54       0.42      0.38      0.40       116\n",
      "          55       0.56      0.83      0.67        99\n",
      "          56       0.26      0.37      0.31        46\n",
      "          57       0.39      0.76      0.51        38\n",
      "          58       0.34      0.60      0.44        53\n",
      "          59       0.14      0.07      0.10       160\n",
      "\n",
      "   micro avg       0.27      0.37      0.31      3991\n",
      "   macro avg       0.23      0.35      0.27      3991\n",
      "weighted avg       0.27      0.37      0.31      3991\n",
      " samples avg       0.25      0.37      0.27      3991\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Metrics for TF-IDF:')\n",
    "print(classification_report(y_val, tf_idf_y_pred_val, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate `recall@k`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall@k on TF-IDF: 0.5186\n"
     ]
    }
   ],
   "source": [
    "tf_idf_recallk = recallk(tf_idf_df_val.tags, tf_idf_df_val.predicted_tags, k=10)\n",
    "print(f'Recall@k on TF-IDF: {tf_idf_recallk:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3. Training on TF-IDF with N-grams:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\decique\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "X_train = [' '.join(txt) for txt in data_train.text_markdown]\n",
    "X_val = [' '.join(txt) for txt in data_val.text_markdown]\n",
    "X_test = [' '.join(txt) for txt in data_test.text_markdown]\n",
    "\n",
    "Tfidf_Vec = TfidfVectorizer(tokenizer = lambda x: x.split(), ngram_range=(1, 2))\n",
    "\n",
    "Tfidf_Vec.fit(X_train)\n",
    "X_train = Tfidf_Vec.transform(X_train)\n",
    "X_test = Tfidf_Vec.transform(X_test)\n",
    "X_val = Tfidf_Vec.transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X TF-IDF with n-grams's shapes:\n",
      "   • X train shape: (25209, 1654803)\n",
      "   • X val shape: (2821, 1654803)\n",
      "   • X test shape: (3119, 1654803)\n"
     ]
    }
   ],
   "source": [
    "print(\"X TF-IDF with n-grams's shapes:\")\n",
    "print(f'   • X train shape: {X_train.shape}')\n",
    "print(f'   • X val shape: {X_val.shape}')\n",
    "print(f'   • X test shape: {X_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_ovr = OneVsRestClassifier(estimator=xgb.XGBClassifier(tree_method='auto',\n",
    "                                                          n_estimators=3,\n",
    "                                                          max_depth=13,\n",
    "                                                          learning_rate=1e5,\n",
    "                                                          objective='binary:logistic',\n",
    "                                                          random_state=42),\n",
    "                              n_jobs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isfile(save_models_path + 'tf_idf_ngrams.joblib'):\n",
    "    clf_ovr = load(save_models_path + 'tf_idf_ngrams.joblib')\n",
    "else:\n",
    "    clf_ovr.fit(X_train, y_train)\n",
    "    dump(clf_ovr, save_models_path + 'tf_idf_ngrams.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_gram_tf_idf_y_pred_val = clf_ovr.predict(X_val)\n",
    "n_gram_tf_idf_y_probas = clf_ovr.predict_proba(X_val)\n",
    "n_gram_tf_idf_y_labels = sorted_labels(n_gram_tf_idf_y_pred_val, n_gram_tf_idf_y_probas, Vec)\n",
    "\n",
    "n_gram_tf_idf_df_val = data_val.copy()\n",
    "n_gram_tf_idf_df_val['predicted_tags'] = n_gram_tf_idf_y_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text_markdown</th>\n",
       "      <th>tags</th>\n",
       "      <th>predicted_tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>421</th>\n",
       "      <td>6992880</td>\n",
       "      <td>[популярный, пк, игра, создавать, устройство, проходить, картинка, память, оставаться, различный, создавать, написать, догадка...</td>\n",
       "      <td>[помогите найти]</td>\n",
       "      <td>[игры]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432</th>\n",
       "      <td>6992917</td>\n",
       "      <td>[профессия, оказываться, сопровождать, образование, курсы, обязанность, входить, хотеться, разговор, зажигать, свеча, оказыват...</td>\n",
       "      <td>[психология]</td>\n",
       "      <td>[ищу книгу, психология, работа]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>578</th>\n",
       "      <td>6994231</td>\n",
       "      <td>[предыдущий, пост, бригада, график, переписывать, месяц, дата, окончание, поездка, графика, случаться, называть, двойной, поез...</td>\n",
       "      <td>[юмор, реальная история из жизни]</td>\n",
       "      <td>[любовь, работа]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>591</th>\n",
       "      <td>6992488</td>\n",
       "      <td>[широкий, хотеться, обращать, внимание, инцидент, связанный, дтп, участие, пожарный, двигаться, оперативный, вызов, включать, ...</td>\n",
       "      <td>[помощь]</td>\n",
       "      <td>[лига юристов, помощь]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>807</th>\n",
       "      <td>7021892</td>\n",
       "      <td>[история, скоро, девушка, упасть, дерево, парень, неловко, улыбаться, следовать, забывать, следить, окружение, темно, отзывать...</td>\n",
       "      <td>[рассказ, фантастика, мат]</td>\n",
       "      <td>[авторский рассказ, девушки, рассказ, реальная история из жизни, фантастика]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  \\\n",
       "421  6992880   \n",
       "432  6992917   \n",
       "578  6994231   \n",
       "591  6992488   \n",
       "807  7021892   \n",
       "\n",
       "                                                                                                                         text_markdown  \\\n",
       "421  [популярный, пк, игра, создавать, устройство, проходить, картинка, память, оставаться, различный, создавать, написать, догадка...   \n",
       "432  [профессия, оказываться, сопровождать, образование, курсы, обязанность, входить, хотеться, разговор, зажигать, свеча, оказыват...   \n",
       "578  [предыдущий, пост, бригада, график, переписывать, месяц, дата, окончание, поездка, графика, случаться, называть, двойной, поез...   \n",
       "591  [широкий, хотеться, обращать, внимание, инцидент, связанный, дтп, участие, пожарный, двигаться, оперативный, вызов, включать, ...   \n",
       "807  [история, скоро, девушка, упасть, дерево, парень, неловко, улыбаться, следовать, забывать, следить, окружение, темно, отзывать...   \n",
       "\n",
       "                                  tags  \\\n",
       "421                   [помогите найти]   \n",
       "432                       [психология]   \n",
       "578  [юмор, реальная история из жизни]   \n",
       "591                           [помощь]   \n",
       "807         [рассказ, фантастика, мат]   \n",
       "\n",
       "                                                                   predicted_tags  \n",
       "421                                                                        [игры]  \n",
       "432                                               [ищу книгу, психология, работа]  \n",
       "578                                                              [любовь, работа]  \n",
       "591                                                        [лига юристов, помощь]  \n",
       "807  [авторский рассказ, девушки, рассказ, реальная история из жизни, фантастика]  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_gram_tf_idf_df_val.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for TF-IDF with 1-2 n-grams:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.22      0.60      0.32        25\n",
      "           1       0.23      0.36      0.28        45\n",
      "           2       0.21      0.50      0.30        40\n",
      "           3       0.15      0.30      0.20        27\n",
      "           4       0.24      0.63      0.35        27\n",
      "           5       0.12      0.18      0.14        68\n",
      "           6       0.17      0.40      0.24        40\n",
      "           7       0.18      0.56      0.27        59\n",
      "           8       0.13      0.24      0.17        42\n",
      "           9       0.25      0.47      0.33       113\n",
      "          10       0.15      0.30      0.20        50\n",
      "          11       0.04      0.04      0.04        85\n",
      "          12       0.12      0.10      0.11        72\n",
      "          13       0.37      0.90      0.52        58\n",
      "          14       0.00      0.00      0.00        52\n",
      "          15       0.00      0.00      0.00        28\n",
      "          16       0.12      0.10      0.11       135\n",
      "          17       0.18      0.52      0.27        23\n",
      "          18       0.23      0.72      0.35        25\n",
      "          19       0.34      0.62      0.44        50\n",
      "          20       0.13      0.31      0.18        29\n",
      "          21       0.69      0.77      0.73       164\n",
      "          22       0.39      0.82      0.53        45\n",
      "          23       0.28      0.38      0.32        77\n",
      "          24       0.32      0.44      0.37        32\n",
      "          25       0.10      0.30      0.15        47\n",
      "          26       0.03      0.04      0.03        25\n",
      "          27       0.70      0.64      0.67       218\n",
      "          28       0.21      0.48      0.30        48\n",
      "          29       0.17      0.38      0.24        39\n",
      "          30       0.25      0.66      0.36        38\n",
      "          31       0.06      0.13      0.08        38\n",
      "          32       0.14      0.21      0.17        53\n",
      "          33       0.13      0.25      0.17        57\n",
      "          34       0.33      0.74      0.45        57\n",
      "          35       0.12      0.07      0.09       102\n",
      "          36       0.21      0.37      0.27        90\n",
      "          37       0.12      0.43      0.19        23\n",
      "          38       0.38      0.60      0.47       136\n",
      "          39       0.15      0.44      0.22        45\n",
      "          40       0.36      0.51      0.42       243\n",
      "          41       0.21      0.39      0.28        49\n",
      "          42       0.28      0.45      0.34       113\n",
      "          43       0.38      0.32      0.35       133\n",
      "          44       0.17      0.25      0.20       118\n",
      "          45       0.06      0.19      0.09        31\n",
      "          46       0.14      0.16      0.15       105\n",
      "          47       0.28      0.38      0.32        29\n",
      "          48       0.22      0.45      0.30        29\n",
      "          49       0.17      0.35      0.23        68\n",
      "          50       0.04      0.04      0.04        47\n",
      "          51       0.07      0.23      0.11        22\n",
      "          52       0.27      0.50      0.35        36\n",
      "          53       0.20      0.76      0.31        29\n",
      "          54       0.32      0.57      0.41       116\n",
      "          55       0.55      0.85      0.67        99\n",
      "          56       0.35      0.39      0.37        46\n",
      "          57       0.32      0.82      0.46        38\n",
      "          58       0.33      0.87      0.48        53\n",
      "          59       0.19      0.11      0.14       160\n",
      "\n",
      "   micro avg       0.26      0.42      0.32      3991\n",
      "   macro avg       0.22      0.41      0.28      3991\n",
      "weighted avg       0.27      0.42      0.32      3991\n",
      " samples avg       0.26      0.41      0.29      3991\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Metrics for TF-IDF with 1-2 n-grams:')\n",
    "print(classification_report(y_val, n_gram_tf_idf_y_pred_val, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate `recall@k`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall@k for TF-IDF with 1-2 n-grams: 0.5874\n"
     ]
    }
   ],
   "source": [
    "n_gram_tf_idf_recallk = recallk(n_gram_tf_idf_df_val.tags, n_gram_tf_idf_df_val.predicted_tags, k=10)\n",
    "print(f'Recall@k for TF-IDF with 1-2 n-grams: {n_gram_tf_idf_recallk:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4. Training on rubert-tiny-v2 embeddings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_paths = module_path + '/data/embeddings/rubert-tiny-v2/'\n",
    "\n",
    "emb_pth = [emb_paths + 'texts.parquet']\n",
    "emb = merge_dataset(emb_pth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2936217</td>\n",
       "      <td>[0.3411005, -0.16877297, -0.3599054, 0.011505239, -0.19693527, 0.16206133, -0.62560713, -0.38459125, -0.08364315, -0.17384137,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6991412</td>\n",
       "      <td>[0.3696494, 0.06409113, -0.62138826, -0.8906186, 0.08984075, 0.27482352, -0.31647494, -0.778525, -0.6068895, 0.42193377, -0.05...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6991359</td>\n",
       "      <td>[0.3278318, 0.08586374, -0.7452521, -0.2529353, -0.32851255, 0.5415312, -0.53284395, -1.2018805, 0.120118916, 0.15034527, -0.3...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  \\\n",
       "0  2936217   \n",
       "1  6991412   \n",
       "2  6991359   \n",
       "\n",
       "                                                                                                                           embedding  \n",
       "0  [0.3411005, -0.16877297, -0.3599054, 0.011505239, -0.19693527, 0.16206133, -0.62560713, -0.38459125, -0.08364315, -0.17384137,...  \n",
       "1  [0.3696494, 0.06409113, -0.62138826, -0.8906186, 0.08984075, 0.27482352, -0.31647494, -0.778525, -0.6068895, 0.42193377, -0.05...  \n",
       "2  [0.3278318, 0.08586374, -0.7452521, -0.2529353, -0.32851255, 0.5415312, -0.53284395, -1.2018805, 0.120118916, 0.15034527, -0.3...  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb = emb[emb['id'].isin(data['id'])]\n",
    "\n",
    "emb_train = emb[emb['id'].isin(data_train['id'])]\n",
    "emb_val = emb[emb['id'].isin(data_val['id'])]\n",
    "emb_test = emb[emb['id'].isin(data_test['id'])]\n",
    "\n",
    "assert len(emb_train) == len(data_train), \"Something went wrong!\"\n",
    "assert len(emb_val) == len(data_val), \"Something went wrong!\"\n",
    "assert len(emb_test) == len(data_test), \"Something went wrong!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_emb = [i for i in emb_train.embedding]\n",
    "X_val_emb = [i for i in emb_val.embedding]\n",
    "X_test_emb = [i for i in emb_test.embedding]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X embeddings shapes:\n",
      "   • X train shape: (25209, 312)\n",
      "   • X val shape: (2821, 312)\n",
      "   • X test shape: (3119, 312)\n"
     ]
    }
   ],
   "source": [
    "print(\"X embeddings shapes:\")\n",
    "print(f'   • X train shape: {np.shape(X_train_emb)}')\n",
    "print(f'   • X val shape: {np.shape(X_val_emb)}')\n",
    "print(f'   • X test shape: {np.shape(X_test_emb)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_ovr = OneVsRestClassifier(estimator=xgb.XGBClassifier(tree_method='auto',\n",
    "                                                          n_estimators=5,\n",
    "                                                          max_depth=20,\n",
    "                                                          learning_rate=1e5,\n",
    "                                                          objective='binary:logistic',\n",
    "                                                          random_state=42),\n",
    "                              n_jobs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isfile(save_models_path + 'rubert.joblib'):\n",
    "    clf_ovr = load(save_models_path + 'rubert.joblib')\n",
    "else:\n",
    "    clf_ovr.fit(X_train_emb, y_train)\n",
    "    dump(clf_ovr, save_models_path + 'rubert.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "rubert_y_pred_val = clf_ovr.predict(X_val_emb)\n",
    "rubert_y_probas = clf_ovr.predict_proba(X_val_emb)\n",
    "rubert_y_labels = sorted_labels(rubert_y_pred_val, rubert_y_probas, Vec)\n",
    "\n",
    "rubert_df_val = data_val.copy()\n",
    "rubert_df_val['predicted_tags'] = rubert_y_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text_markdown</th>\n",
       "      <th>tags</th>\n",
       "      <th>predicted_tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>421</th>\n",
       "      <td>6992880</td>\n",
       "      <td>[популярный, пк, игра, создавать, устройство, проходить, картинка, память, оставаться, различный, создавать, написать, догадка...</td>\n",
       "      <td>[помогите найти]</td>\n",
       "      <td>[игры, помогите найти]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432</th>\n",
       "      <td>6992917</td>\n",
       "      <td>[профессия, оказываться, сопровождать, образование, курсы, обязанность, входить, хотеться, разговор, зажигать, свеча, оказыват...</td>\n",
       "      <td>[психология]</td>\n",
       "      <td>[вопрос]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>578</th>\n",
       "      <td>6994231</td>\n",
       "      <td>[предыдущий, пост, бригада, график, переписывать, месяц, дата, окончание, поездка, графика, случаться, называть, двойной, поез...</td>\n",
       "      <td>[юмор, реальная история из жизни]</td>\n",
       "      <td>[жизнь, история, мат, работа, реальная история из жизни]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>591</th>\n",
       "      <td>6992488</td>\n",
       "      <td>[широкий, хотеться, обращать, внимание, инцидент, связанный, дтп, участие, пожарный, двигаться, оперативный, вызов, включать, ...</td>\n",
       "      <td>[помощь]</td>\n",
       "      <td>[армия, новости, помогите найти, помощь]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>807</th>\n",
       "      <td>7021892</td>\n",
       "      <td>[история, скоро, девушка, упасть, дерево, парень, неловко, улыбаться, следовать, забывать, следить, окружение, темно, отзывать...</td>\n",
       "      <td>[рассказ, фантастика, мат]</td>\n",
       "      <td>[авторский рассказ, история, книги, мат, рассказ, реальная история из жизни, фантастика]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  \\\n",
       "421  6992880   \n",
       "432  6992917   \n",
       "578  6994231   \n",
       "591  6992488   \n",
       "807  7021892   \n",
       "\n",
       "                                                                                                                         text_markdown  \\\n",
       "421  [популярный, пк, игра, создавать, устройство, проходить, картинка, память, оставаться, различный, создавать, написать, догадка...   \n",
       "432  [профессия, оказываться, сопровождать, образование, курсы, обязанность, входить, хотеться, разговор, зажигать, свеча, оказыват...   \n",
       "578  [предыдущий, пост, бригада, график, переписывать, месяц, дата, окончание, поездка, графика, случаться, называть, двойной, поез...   \n",
       "591  [широкий, хотеться, обращать, внимание, инцидент, связанный, дтп, участие, пожарный, двигаться, оперативный, вызов, включать, ...   \n",
       "807  [история, скоро, девушка, упасть, дерево, парень, неловко, улыбаться, следовать, забывать, следить, окружение, темно, отзывать...   \n",
       "\n",
       "                                  tags  \\\n",
       "421                   [помогите найти]   \n",
       "432                       [психология]   \n",
       "578  [юмор, реальная история из жизни]   \n",
       "591                           [помощь]   \n",
       "807         [рассказ, фантастика, мат]   \n",
       "\n",
       "                                                                               predicted_tags  \n",
       "421                                                                    [игры, помогите найти]  \n",
       "432                                                                                  [вопрос]  \n",
       "578                                  [жизнь, история, мат, работа, реальная история из жизни]  \n",
       "591                                                  [армия, новости, помогите найти, помощь]  \n",
       "807  [авторский рассказ, история, книги, мат, рассказ, реальная история из жизни, фантастика]  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rubert_df_val.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for rubert embeddings:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.06      0.16      0.09        25\n",
      "           1       0.17      0.33      0.22        45\n",
      "           2       0.15      0.23      0.18        40\n",
      "           3       0.03      0.07      0.04        27\n",
      "           4       0.08      0.19      0.11        27\n",
      "           5       0.08      0.19      0.11        68\n",
      "           6       0.10      0.12      0.11        40\n",
      "           7       0.10      0.22      0.14        59\n",
      "           8       0.11      0.17      0.13        42\n",
      "           9       0.10      0.23      0.14       113\n",
      "          10       0.10      0.22      0.13        50\n",
      "          11       0.05      0.11      0.07        85\n",
      "          12       0.05      0.11      0.07        72\n",
      "          13       0.21      0.40      0.27        58\n",
      "          14       0.04      0.12      0.06        52\n",
      "          15       0.01      0.04      0.02        28\n",
      "          16       0.09      0.20      0.12       135\n",
      "          17       0.15      0.35      0.21        23\n",
      "          18       0.17      0.44      0.24        25\n",
      "          19       0.09      0.22      0.13        50\n",
      "          20       0.12      0.31      0.17        29\n",
      "          21       0.25      0.45      0.32       164\n",
      "          22       0.14      0.36      0.20        45\n",
      "          23       0.14      0.19      0.16        77\n",
      "          24       0.12      0.22      0.16        32\n",
      "          25       0.05      0.17      0.08        47\n",
      "          26       0.05      0.12      0.07        25\n",
      "          27       0.19      0.38      0.25       218\n",
      "          28       0.14      0.27      0.18        48\n",
      "          29       0.05      0.10      0.07        39\n",
      "          30       0.07      0.08      0.07        38\n",
      "          31       0.07      0.13      0.09        38\n",
      "          32       0.08      0.19      0.11        53\n",
      "          33       0.22      0.37      0.27        57\n",
      "          34       0.08      0.16      0.11        57\n",
      "          35       0.07      0.13      0.09       102\n",
      "          36       0.14      0.27      0.18        90\n",
      "          37       0.05      0.13      0.07        23\n",
      "          38       0.20      0.27      0.23       136\n",
      "          39       0.13      0.29      0.18        45\n",
      "          40       0.25      0.38      0.31       243\n",
      "          41       0.17      0.31      0.22        49\n",
      "          42       0.18      0.35      0.24       113\n",
      "          43       0.22      0.35      0.27       133\n",
      "          44       0.09      0.23      0.13       118\n",
      "          45       0.03      0.06      0.04        31\n",
      "          46       0.13      0.25      0.17       105\n",
      "          47       0.03      0.03      0.03        29\n",
      "          48       0.03      0.07      0.04        29\n",
      "          49       0.12      0.21      0.15        68\n",
      "          50       0.03      0.09      0.05        47\n",
      "          51       0.01      0.05      0.02        22\n",
      "          52       0.13      0.22      0.16        36\n",
      "          53       0.01      0.03      0.02        29\n",
      "          54       0.42      0.59      0.49       116\n",
      "          55       0.27      0.48      0.34        99\n",
      "          56       0.13      0.26      0.17        46\n",
      "          57       0.08      0.16      0.11        38\n",
      "          58       0.15      0.34      0.21        53\n",
      "          59       0.08      0.17      0.11       160\n",
      "\n",
      "   micro avg       0.13      0.26      0.18      3991\n",
      "   macro avg       0.11      0.22      0.15      3991\n",
      "weighted avg       0.14      0.26      0.18      3991\n",
      " samples avg       0.14      0.27      0.16      3991\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Metrics for rubert embeddings:')\n",
    "print(classification_report(y_val, rubert_y_pred_val, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate `recall@k`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall@k for model with rubert embeddings: 0.3701\n"
     ]
    }
   ],
   "source": [
    "rubert_recallk = recallk(rubert_df_val.tags, rubert_df_val.predicted_tags, k=10)\n",
    "print(f'Recall@k for model with rubert embeddings: {rubert_recallk:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 3. Results\n",
    "\n",
    "As the result of training with different embeddings, we have the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall@k's with k=10 for models:\n",
      "\n",
      "Recall@k for Bag-of-Words: 0.548742\n",
      "Recall@k for TF-IDF: 0.518610\n",
      "Recall@k for TF-IDF with uni- and bi- grams: 0.587380\n",
      "Recall@k for rubert embeddings: 0.370082\n"
     ]
    }
   ],
   "source": [
    "print(\"Recall@k's with k=10 for models:\\n\")\n",
    "print(f'Recall@k for Bag-of-Words: {bow_recallk:3f}')\n",
    "print(f'Recall@k for TF-IDF: {tf_idf_recallk:3f}')\n",
    "print(f'Recall@k for TF-IDF with uni- and bi- grams: {n_gram_tf_idf_recallk:3f}')\n",
    "print(f'Recall@k for rubert embeddings: {rubert_recallk:3f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
