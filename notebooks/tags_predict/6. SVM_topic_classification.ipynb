{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machine for topic classification\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "module_path = os.path.abspath(os.path.join('..\\..')) # Path to root folder\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path + \"/scripts\") # define scripts path\n",
    "\n",
    "from ipynb_func import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data loader:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NUM = 10 # Number of data parquets to use\n",
    "#assert NUM >= 1 and NUM <= 10, \"NUM value must be in range [1, 10]\"\n",
    "\n",
    "# Making list of roots to merge processed raw data \n",
    "#paths = [module_path + f\"/data/pikabu/tag_processed/raw_data/{i}_tag_processed.parquet\" for i in range(NUM)] \n",
    "\n",
    "# Making list of roots to merge processed filtered data\n",
    "#paths = [module_path + f\"/data/pikabu/tag_processed/filtered_data/{i}_tag_processed.parquet\" for i in range(NUM)] \n",
    "\n",
    "# Making list of roots to merge processed cleared data\n",
    "paths = [module_path + f\"/data/pikabu/splited_data/cleared_texts.parquet\"] \n",
    "\n",
    "data = merge_dataset(paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text_markdown</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>6991359</td>\n",
       "      <td>[добрый, сутки, господин, дама, подсказывать, название, игра, телефон, оформление, убийство, зомби, очки, ездить, машинка, кру...</td>\n",
       "      <td>[игры, поиск]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>7004423</td>\n",
       "      <td>[ехать, девчонка, школа, оставаться, свободный, макс, заявка, прямой, конечный, адрес, железнодорожный, институт, включать, вб...</td>\n",
       "      <td>[юмор]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>6991603</td>\n",
       "      <td>[стадо, стадо, гигантский, случаться, стадо, управлять, волк, предел, волк, жопа, враг, дружно, осматривать, выдавливать, стад...</td>\n",
       "      <td>[мат]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  \\\n",
       "15  6991359   \n",
       "37  7004423   \n",
       "52  6991603   \n",
       "\n",
       "                                                                                                                        text_markdown  \\\n",
       "15  [добрый, сутки, господин, дама, подсказывать, название, игра, телефон, оформление, убийство, зомби, очки, ездить, машинка, кру...   \n",
       "37  [ехать, девчонка, школа, оставаться, свободный, макс, заявка, прямой, конечный, адрес, железнодорожный, институт, включать, вб...   \n",
       "52  [стадо, стадо, гигантский, случаться, стадо, управлять, волк, предел, волк, жопа, враг, дружно, осматривать, выдавливать, стад...   \n",
       "\n",
       "             tags  \n",
       "15  [игры, поиск]  \n",
       "37         [юмор]  \n",
       "52          [мат]  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', 130)\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 1. Data preparation and split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(module_path + f\"/data/pikabu/splited_data/indexes.json\") as f:\n",
    "    id_splits = f.read()\n",
    "\n",
    "id_splits = json.loads(id_splits)\n",
    "\n",
    "data_train = data[data['id'].isin(id_splits['train'])]\n",
    "data_val = data[data['id'].isin(id_splits['val'])]\n",
    "data_test = data[data['id'].isin(id_splits['test'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train data: 25209\n",
      "Number of val data: 2821\n",
      "Number of test data: 3119\n",
      "Distribution: 81 / 9 / 10\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of train data: {len(data_train)}\")\n",
    "print(f\"Number of val data: {len(data_val)}\")\n",
    "print(f\"Number of test data: {len(data_test)}\")\n",
    "print(f\"Distribution: {len(data_train)/len(data)*100:.0f} / {len(data_val)/len(data)*100:.0f} / {len(data_test)/len(data)*100:.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 2. Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "from joblib import dump, load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Target preparation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\decique\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "Vec = CountVectorizer(tokenizer=lambda x: x.split(','), binary=True)\n",
    "\n",
    "df = data.copy()\n",
    "df.tags = [','.join(i) for i in df.tags]\n",
    "\n",
    "df_train = data_train.copy()\n",
    "df_train.tags = [','.join(i) for i in df_train.tags]\n",
    "\n",
    "df_val = data_val.copy()\n",
    "df_val.tags = [','.join(i) for i in df_val.tags]\n",
    "\n",
    "df_test = data_test.copy()\n",
    "df_test.tags = [','.join(i) for i in df_test.tags]\n",
    "\n",
    "y_data = Vec.fit(df['tags'])\n",
    "y_train = Vec.transform(df_train['tags'])\n",
    "y_val = Vec.transform(df_val['tags'])\n",
    "y_test = Vec.transform(df_test['tags'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tags to predict:\n",
      "['авто' 'авторский рассказ' 'алкоголь' 'анекдот' 'армия' 'вопрос' 'врачи'\n",
      " 'девушки' 'деньги' 'дети' 'детство' 'другое' 'жизнь' 'игры' 'интересное'\n",
      " 'истории' 'история' 'ищу книгу' 'ищу фильм' 'карантин' 'книги'\n",
      " 'коронавирус' 'кот' 'лига добра' 'лига юристов' 'любовь' 'люди' 'мат'\n",
      " 'медицина' 'москва' 'музыка' 'мысли' 'негатив' 'новости' 'новый год'\n",
      " 'общество' 'отношения' 'поиск' 'политика' 'помогите найти' 'помощь'\n",
      " 'психология' 'работа' 'рассказ' 'реальная история из жизни'\n",
      " 'родители и дети' 'россия' 'самоизоляция' 'санкт-петербург' 'семья'\n",
      " 'случай из жизни' 'совет' 'сон' 'соседи' 'стихи' 'украина' 'фантастика'\n",
      " 'фильмы' 'школа' 'юмор']\n"
     ]
    }
   ],
   "source": [
    "print('Tags to predict:')\n",
    "print(Vec.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_distr = getworddict(getwordlist(data.tags))\n",
    "tag_distr_formated = {}\n",
    "for i in range(len(tag_distr)):\n",
    "    tag_distr_formated[i] = round(tag_distr[Vec.get_feature_names_out()[i]] / sum(tag_distr.values()), 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tags weights:\n",
      "{0: 0.0073, 1: 0.0121, 2: 0.0075, 3: 0.0079, 4: 0.0085, 5: 0.0196, 6: 0.0077, 7: 0.0138, 8: 0.0089, 9: 0.0279, 10: 0.011, 11: 0.0221, 12: 0.0186, 13: 0.0122, 14: 0.0122, 15: 0.0086, 16: 0.0338, 17: 0.0067, 18: 0.008, 19: 0.014, 20: 0.0107, 21: 0.0454, 22: 0.0121, 23: 0.0142, 24: 0.0078, 25: 0.0149, 26: 0.0084, 27: 0.0549, 28: 0.0125, 29: 0.0098, 30: 0.0081, 31: 0.0093, 32: 0.0145, 33: 0.0152, 34: 0.0133, 35: 0.0237, 36: 0.0206, 37: 0.0071, 38: 0.0308, 39: 0.0118, 40: 0.054, 41: 0.0121, 42: 0.0297, 43: 0.0303, 44: 0.0315, 45: 0.0082, 46: 0.0277, 47: 0.0063, 48: 0.0075, 49: 0.0145, 50: 0.0122, 51: 0.0078, 52: 0.0067, 53: 0.0086, 54: 0.0274, 55: 0.0275, 56: 0.0111, 57: 0.0104, 58: 0.0144, 59: 0.0384}\n"
     ]
    }
   ],
   "source": [
    "print('Tags weights:')\n",
    "print(tag_distr_formated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y shapes:\n",
      "  • Y train: (25209, 60)\n",
      "  • Y validation: (2821, 60)\n",
      "  • Y test: (3119, 60)\n"
     ]
    }
   ],
   "source": [
    "print('Y shapes:')\n",
    "print(f'  • Y train: {y_train.shape}')\n",
    "print(f'  • Y validation: {y_val.shape}')\n",
    "print(f'  • Y test: {y_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Training with bag-of-words embeddings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_models_path = module_path + '/models/svm/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data = [' '.join(txt) for txt in data.text_markdown]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = [' '.join(txt) for txt in data_train.text_markdown]\n",
    "X_val = [' '.join(txt) for txt in data_val.text_markdown]\n",
    "X_test = [' '.join(txt) for txt in data_test.text_markdown]\n",
    "\n",
    "X_Vec = CountVectorizer(tokenizer = lambda x: x.split())\n",
    "\n",
    "X_Vec.fit(X_train)\n",
    "X_train = X_Vec.transform(X_train)\n",
    "X_test = X_Vec.transform(X_test)\n",
    "X_val = X_Vec.transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X BoW's shapes:\n",
      "   • X train shape: (25209, 5899)\n",
      "   • X val shape: (2821, 5899)\n",
      "   • X test shape: (3119, 5899)\n"
     ]
    }
   ],
   "source": [
    "print(\"X BoW's shapes:\")\n",
    "print(f'   • X train shape: {X_train.shape}')\n",
    "print(f'   • X val shape: {X_val.shape}')\n",
    "print(f'   • X test shape: {X_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_ovr = OneVsRestClassifier(estimator=LinearSVC(penalty='l2',\n",
    "                                                  loss='squared_hinge',\n",
    "                                                  dual='auto',\n",
    "                                                  C=1e3,\n",
    "                                                  multi_class='ovr',\n",
    "                                                  #class_weight=tag_distr_formated,\n",
    "                                                  random_state=42),\n",
    "                              n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isfile(save_models_path + 'bow.joblib'):\n",
    "    clf_ovr = load(save_models_path + 'bow.joblib')\n",
    "else:\n",
    "    clf_ovr.fit(X_train, y_train)\n",
    "    dump(clf_ovr, save_models_path + 'bow.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_y_pred_val = clf_ovr.predict(X_val)\n",
    "\n",
    "bow_df_val = data_val.copy()\n",
    "bow_df_val['predicted_tags'] = Vec.inverse_transform(bow_y_pred_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text_markdown</th>\n",
       "      <th>tags</th>\n",
       "      <th>predicted_tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>421</th>\n",
       "      <td>6992880</td>\n",
       "      <td>[популярный, пк, игра, создавать, устройство, проходить, картинка, память, оставаться, различный, создавать, написать, догадка...</td>\n",
       "      <td>[помогите найти]</td>\n",
       "      <td>[помогите найти]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432</th>\n",
       "      <td>6992917</td>\n",
       "      <td>[профессия, оказываться, сопровождать, образование, курсы, обязанность, входить, хотеться, разговор, зажигать, свеча, оказыват...</td>\n",
       "      <td>[психология]</td>\n",
       "      <td>[работа]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>578</th>\n",
       "      <td>6994231</td>\n",
       "      <td>[предыдущий, пост, бригада, график, переписывать, месяц, дата, окончание, поездка, графика, случаться, называть, двойной, поез...</td>\n",
       "      <td>[юмор, реальная история из жизни]</td>\n",
       "      <td>[девушки, мат, случай из жизни]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>591</th>\n",
       "      <td>6992488</td>\n",
       "      <td>[широкий, хотеться, обращать, внимание, инцидент, связанный, дтп, участие, пожарный, двигаться, оперативный, вызов, включать, ...</td>\n",
       "      <td>[помощь]</td>\n",
       "      <td>[лига юристов, новости]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>807</th>\n",
       "      <td>7021892</td>\n",
       "      <td>[история, скоро, девушка, упасть, дерево, парень, неловко, улыбаться, следовать, забывать, следить, окружение, темно, отзывать...</td>\n",
       "      <td>[рассказ, фантастика, мат]</td>\n",
       "      <td>[авторский рассказ, история, рассказ, фантастика]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  \\\n",
       "421  6992880   \n",
       "432  6992917   \n",
       "578  6994231   \n",
       "591  6992488   \n",
       "807  7021892   \n",
       "\n",
       "                                                                                                                         text_markdown  \\\n",
       "421  [популярный, пк, игра, создавать, устройство, проходить, картинка, память, оставаться, различный, создавать, написать, догадка...   \n",
       "432  [профессия, оказываться, сопровождать, образование, курсы, обязанность, входить, хотеться, разговор, зажигать, свеча, оказыват...   \n",
       "578  [предыдущий, пост, бригада, график, переписывать, месяц, дата, окончание, поездка, графика, случаться, называть, двойной, поез...   \n",
       "591  [широкий, хотеться, обращать, внимание, инцидент, связанный, дтп, участие, пожарный, двигаться, оперативный, вызов, включать, ...   \n",
       "807  [история, скоро, девушка, упасть, дерево, парень, неловко, улыбаться, следовать, забывать, следить, окружение, темно, отзывать...   \n",
       "\n",
       "                                  tags  \\\n",
       "421                   [помогите найти]   \n",
       "432                       [психология]   \n",
       "578  [юмор, реальная история из жизни]   \n",
       "591                           [помощь]   \n",
       "807         [рассказ, фантастика, мат]   \n",
       "\n",
       "                                        predicted_tags  \n",
       "421                                   [помогите найти]  \n",
       "432                                           [работа]  \n",
       "578                    [девушки, мат, случай из жизни]  \n",
       "591                            [лига юристов, новости]  \n",
       "807  [авторский рассказ, история, рассказ, фантастика]  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_df_val.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for Bag-of-Words:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      0.40      0.35        25\n",
      "           1       0.23      0.22      0.22        45\n",
      "           2       0.48      0.33      0.39        40\n",
      "           3       0.19      0.26      0.22        27\n",
      "           4       0.42      0.41      0.42        27\n",
      "           5       0.09      0.15      0.11        68\n",
      "           6       0.36      0.33      0.34        40\n",
      "           7       0.22      0.29      0.25        59\n",
      "           8       0.08      0.10      0.09        42\n",
      "           9       0.24      0.33      0.28       113\n",
      "          10       0.24      0.26      0.25        50\n",
      "          11       0.04      0.07      0.05        85\n",
      "          12       0.06      0.11      0.08        72\n",
      "          13       0.45      0.50      0.48        58\n",
      "          14       0.02      0.02      0.02        52\n",
      "          15       0.00      0.00      0.00        28\n",
      "          16       0.12      0.16      0.14       135\n",
      "          17       0.39      0.30      0.34        23\n",
      "          18       0.28      0.44      0.34        25\n",
      "          19       0.21      0.28      0.24        50\n",
      "          20       0.18      0.24      0.21        29\n",
      "          21       0.63      0.68      0.66       164\n",
      "          22       0.51      0.40      0.45        45\n",
      "          23       0.24      0.26      0.25        77\n",
      "          24       0.42      0.44      0.43        32\n",
      "          25       0.15      0.28      0.19        47\n",
      "          26       0.02      0.04      0.02        25\n",
      "          27       0.30      0.38      0.33       218\n",
      "          28       0.27      0.31      0.29        48\n",
      "          29       0.12      0.18      0.14        39\n",
      "          30       0.39      0.39      0.39        38\n",
      "          31       0.11      0.11      0.11        38\n",
      "          32       0.12      0.13      0.12        53\n",
      "          33       0.28      0.30      0.29        57\n",
      "          34       0.48      0.53      0.50        57\n",
      "          35       0.10      0.14      0.12       102\n",
      "          36       0.22      0.24      0.23        90\n",
      "          37       0.08      0.09      0.08        23\n",
      "          38       0.39      0.40      0.39       136\n",
      "          39       0.12      0.16      0.13        45\n",
      "          40       0.33      0.39      0.36       243\n",
      "          41       0.30      0.33      0.31        49\n",
      "          42       0.29      0.40      0.34       113\n",
      "          43       0.29      0.29      0.29       133\n",
      "          44       0.13      0.21      0.16       118\n",
      "          45       0.11      0.16      0.13        31\n",
      "          46       0.15      0.21      0.18       105\n",
      "          47       0.18      0.14      0.16        29\n",
      "          48       0.11      0.14      0.12        29\n",
      "          49       0.23      0.24      0.23        68\n",
      "          50       0.00      0.00      0.00        47\n",
      "          51       0.02      0.05      0.03        22\n",
      "          52       0.35      0.22      0.27        36\n",
      "          53       0.37      0.38      0.37        29\n",
      "          54       0.55      0.53      0.54       116\n",
      "          55       0.59      0.58      0.58        99\n",
      "          56       0.33      0.33      0.33        46\n",
      "          57       0.45      0.47      0.46        38\n",
      "          58       0.44      0.45      0.44        53\n",
      "          59       0.15      0.20      0.17       160\n",
      "\n",
      "   micro avg       0.25      0.30      0.27      3991\n",
      "   macro avg       0.25      0.27      0.26      3991\n",
      "weighted avg       0.27      0.30      0.28      3991\n",
      " samples avg       0.23      0.31      0.24      3991\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Metrics for Bag-of-Words:')\n",
    "print(classification_report(y_val, bow_y_pred_val, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate `recall@k`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean recall@k for k=5 for Bag-of-Words: 0.308\n"
     ]
    }
   ],
   "source": [
    "K = 5\n",
    "bow_recallk_mean, bow_recallk_med = recallk(bow_df_val.tags, bow_df_val.predicted_tags, k=K)\n",
    "\n",
    "print(f'Mean recall@k for k={K} for Bag-of-Words: {bow_recallk_mean:.3f}')\n",
    "#print(f'Median recall@k for k={K} for Bag-of-Words: {bow_recallk_med:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Training with IF-IDF embeddings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\decique\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "X_train = [' '.join(txt) for txt in data_train.text_markdown]\n",
    "X_val = [' '.join(txt) for txt in data_val.text_markdown]\n",
    "X_test = [' '.join(txt) for txt in data_test.text_markdown]\n",
    "\n",
    "Tfidf_Vec = TfidfVectorizer(tokenizer = lambda x: x.split())\n",
    "\n",
    "Tfidf_Vec.fit(X_train)\n",
    "X_train = Tfidf_Vec.transform(X_train)\n",
    "X_test = Tfidf_Vec.transform(X_test)\n",
    "X_val = Tfidf_Vec.transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X TF-IDF's shapes:\n",
      "   • X train shape: (25209, 5899)\n",
      "   • X val shape: (2821, 5899)\n",
      "   • X test shape: (3119, 5899)\n"
     ]
    }
   ],
   "source": [
    "print(\"X TF-IDF's shapes:\")\n",
    "print(f'   • X train shape: {X_train.shape}')\n",
    "print(f'   • X val shape: {X_val.shape}')\n",
    "print(f'   • X test shape: {X_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_ovr = OneVsRestClassifier(estimator=LinearSVC(penalty='l2',\n",
    "                                                  loss='squared_hinge',\n",
    "                                                  dual='auto',\n",
    "                                                  C=1e3,\n",
    "                                                  multi_class='ovr',\n",
    "                                                  #class_weight=tag_distr_formated,\n",
    "                                                  random_state=42),\n",
    "                              n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isfile(save_models_path + 'tf_idf.joblib'):\n",
    "    clf_ovr = load(save_models_path + 'tf_idf.joblib')\n",
    "else:\n",
    "    clf_ovr.fit(X_train, y_train)\n",
    "    dump(clf_ovr, save_models_path + 'tf_idf.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_y_pred_val = clf_ovr.predict(X_val)\n",
    "\n",
    "tf_idf_df_val = data_val.copy()\n",
    "tf_idf_df_val['predicted_tags'] = Vec.inverse_transform(tf_idf_y_pred_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text_markdown</th>\n",
       "      <th>tags</th>\n",
       "      <th>predicted_tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>421</th>\n",
       "      <td>6992880</td>\n",
       "      <td>[популярный, пк, игра, создавать, устройство, проходить, картинка, память, оставаться, различный, создавать, написать, догадка...</td>\n",
       "      <td>[помогите найти]</td>\n",
       "      <td>[интересное, помогите найти]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432</th>\n",
       "      <td>6992917</td>\n",
       "      <td>[профессия, оказываться, сопровождать, образование, курсы, обязанность, входить, хотеться, разговор, зажигать, свеча, оказыват...</td>\n",
       "      <td>[психология]</td>\n",
       "      <td>[работа]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>578</th>\n",
       "      <td>6994231</td>\n",
       "      <td>[предыдущий, пост, бригада, график, переписывать, месяц, дата, окончание, поездка, графика, случаться, называть, двойной, поез...</td>\n",
       "      <td>[юмор, реальная история из жизни]</td>\n",
       "      <td>[мат]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>591</th>\n",
       "      <td>6992488</td>\n",
       "      <td>[широкий, хотеться, обращать, внимание, инцидент, связанный, дтп, участие, пожарный, двигаться, оперативный, вызов, включать, ...</td>\n",
       "      <td>[помощь]</td>\n",
       "      <td>[лига юристов, новости]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>807</th>\n",
       "      <td>7021892</td>\n",
       "      <td>[история, скоро, девушка, упасть, дерево, парень, неловко, улыбаться, следовать, забывать, следить, окружение, темно, отзывать...</td>\n",
       "      <td>[рассказ, фантастика, мат]</td>\n",
       "      <td>[авторский рассказ, история, рассказ, фантастика]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  \\\n",
       "421  6992880   \n",
       "432  6992917   \n",
       "578  6994231   \n",
       "591  6992488   \n",
       "807  7021892   \n",
       "\n",
       "                                                                                                                         text_markdown  \\\n",
       "421  [популярный, пк, игра, создавать, устройство, проходить, картинка, память, оставаться, различный, создавать, написать, догадка...   \n",
       "432  [профессия, оказываться, сопровождать, образование, курсы, обязанность, входить, хотеться, разговор, зажигать, свеча, оказыват...   \n",
       "578  [предыдущий, пост, бригада, график, переписывать, месяц, дата, окончание, поездка, графика, случаться, называть, двойной, поез...   \n",
       "591  [широкий, хотеться, обращать, внимание, инцидент, связанный, дтп, участие, пожарный, двигаться, оперативный, вызов, включать, ...   \n",
       "807  [история, скоро, девушка, упасть, дерево, парень, неловко, улыбаться, следовать, забывать, следить, окружение, темно, отзывать...   \n",
       "\n",
       "                                  tags  \\\n",
       "421                   [помогите найти]   \n",
       "432                       [психология]   \n",
       "578  [юмор, реальная история из жизни]   \n",
       "591                           [помощь]   \n",
       "807         [рассказ, фантастика, мат]   \n",
       "\n",
       "                                        predicted_tags  \n",
       "421                       [интересное, помогите найти]  \n",
       "432                                           [работа]  \n",
       "578                                              [мат]  \n",
       "591                            [лига юристов, новости]  \n",
       "807  [авторский рассказ, история, рассказ, фантастика]  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf_df_val.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for TF-IDF:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.24      0.29        25\n",
      "           1       0.30      0.24      0.27        45\n",
      "           2       0.65      0.33      0.43        40\n",
      "           3       0.37      0.26      0.30        27\n",
      "           4       0.57      0.44      0.50        27\n",
      "           5       0.11      0.13      0.12        68\n",
      "           6       0.48      0.28      0.35        40\n",
      "           7       0.26      0.25      0.26        59\n",
      "           8       0.07      0.05      0.06        42\n",
      "           9       0.28      0.33      0.30       113\n",
      "          10       0.31      0.20      0.24        50\n",
      "          11       0.03      0.05      0.04        85\n",
      "          12       0.09      0.14      0.11        72\n",
      "          13       0.62      0.48      0.54        58\n",
      "          14       0.03      0.02      0.02        52\n",
      "          15       0.00      0.00      0.00        28\n",
      "          16       0.13      0.19      0.16       135\n",
      "          17       0.54      0.30      0.39        23\n",
      "          18       0.50      0.36      0.42        25\n",
      "          19       0.33      0.32      0.33        50\n",
      "          20       0.37      0.24      0.29        29\n",
      "          21       0.68      0.70      0.69       164\n",
      "          22       0.76      0.42      0.54        45\n",
      "          23       0.32      0.27      0.30        77\n",
      "          24       0.42      0.31      0.36        32\n",
      "          25       0.19      0.21      0.20        47\n",
      "          26       0.04      0.04      0.04        25\n",
      "          27       0.29      0.38      0.33       218\n",
      "          28       0.39      0.29      0.33        48\n",
      "          29       0.18      0.15      0.16        39\n",
      "          30       0.54      0.39      0.45        38\n",
      "          31       0.20      0.08      0.11        38\n",
      "          32       0.17      0.15      0.16        53\n",
      "          33       0.23      0.21      0.22        57\n",
      "          34       0.58      0.49      0.53        57\n",
      "          35       0.11      0.16      0.13       102\n",
      "          36       0.27      0.27      0.27        90\n",
      "          37       0.09      0.04      0.06        23\n",
      "          38       0.37      0.39      0.38       136\n",
      "          39       0.12      0.13      0.13        45\n",
      "          40       0.31      0.38      0.34       243\n",
      "          41       0.37      0.22      0.28        49\n",
      "          42       0.33      0.41      0.37       113\n",
      "          43       0.30      0.30      0.30       133\n",
      "          44       0.14      0.21      0.17       118\n",
      "          45       0.18      0.13      0.15        31\n",
      "          46       0.17      0.22      0.19       105\n",
      "          47       0.29      0.14      0.19        29\n",
      "          48       0.32      0.24      0.27        29\n",
      "          49       0.27      0.26      0.27        68\n",
      "          50       0.00      0.00      0.00        47\n",
      "          51       0.00      0.00      0.00        22\n",
      "          52       0.62      0.22      0.33        36\n",
      "          53       0.45      0.34      0.39        29\n",
      "          54       0.58      0.53      0.56       116\n",
      "          55       0.66      0.61      0.63        99\n",
      "          56       0.58      0.30      0.40        46\n",
      "          57       0.54      0.39      0.45        38\n",
      "          58       0.56      0.38      0.45        53\n",
      "          59       0.13      0.18      0.15       160\n",
      "\n",
      "   micro avg       0.29      0.29      0.29      3991\n",
      "   macro avg       0.32      0.26      0.28      3991\n",
      "weighted avg       0.31      0.29      0.30      3991\n",
      " samples avg       0.25      0.30      0.25      3991\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Metrics for TF-IDF:')\n",
    "print(classification_report(y_val, tf_idf_y_pred_val, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate `recall@k`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean recall@k for k=5 for TF-IDF: 0.299\n"
     ]
    }
   ],
   "source": [
    "tf_idf_recallk_mean, tf_idf_recallk_med = recallk(tf_idf_df_val.tags, tf_idf_df_val.predicted_tags, k=K)\n",
    "\n",
    "print(f'Mean recall@k for k={K} for TF-IDF: {tf_idf_recallk_mean:.3f}')\n",
    "#print(f'Median recall@k for k={K} for TF-IDF: {tf_idf_recallk_med:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3. Training on rubert-tiny-v2 embeddings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_paths = module_path + '/data/embeddings/rubert-tiny-v2/'\n",
    "\n",
    "emb_pth = [emb_paths + 'texts.parquet']\n",
    "emb = merge_dataset(emb_pth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2936217</td>\n",
       "      <td>[0.3411005, -0.16877297, -0.3599054, 0.011505239, -0.19693527, 0.16206133, -0.62560713, -0.38459125, -0.08364315, -0.17384137,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6991412</td>\n",
       "      <td>[0.3696494, 0.06409113, -0.62138826, -0.8906186, 0.08984075, 0.27482352, -0.31647494, -0.778525, -0.6068895, 0.42193377, -0.05...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6991359</td>\n",
       "      <td>[0.3278318, 0.08586374, -0.7452521, -0.2529353, -0.32851255, 0.5415312, -0.53284395, -1.2018805, 0.120118916, 0.15034527, -0.3...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  \\\n",
       "0  2936217   \n",
       "1  6991412   \n",
       "2  6991359   \n",
       "\n",
       "                                                                                                                           embedding  \n",
       "0  [0.3411005, -0.16877297, -0.3599054, 0.011505239, -0.19693527, 0.16206133, -0.62560713, -0.38459125, -0.08364315, -0.17384137,...  \n",
       "1  [0.3696494, 0.06409113, -0.62138826, -0.8906186, 0.08984075, 0.27482352, -0.31647494, -0.778525, -0.6068895, 0.42193377, -0.05...  \n",
       "2  [0.3278318, 0.08586374, -0.7452521, -0.2529353, -0.32851255, 0.5415312, -0.53284395, -1.2018805, 0.120118916, 0.15034527, -0.3...  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb = emb[emb['id'].isin(data['id'])]\n",
    "\n",
    "emb_train = emb[emb['id'].isin(data_train['id'])]\n",
    "emb_val = emb[emb['id'].isin(data_val['id'])]\n",
    "emb_test = emb[emb['id'].isin(data_test['id'])]\n",
    "\n",
    "assert len(emb_train) == len(data_train), \"Something went wrong!\"\n",
    "assert len(emb_val) == len(data_val), \"Something went wrong!\"\n",
    "assert len(emb_test) == len(data_test), \"Something went wrong!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_emb = [i for i in emb_train.embedding]\n",
    "X_val_emb = [i for i in emb_val.embedding]\n",
    "X_test_emb = [i for i in emb_test.embedding]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X embeddings shapes:\n",
      "   • X train shape: (25209, 312)\n",
      "   • X val shape: (2821, 312)\n",
      "   • X test shape: (3119, 312)\n"
     ]
    }
   ],
   "source": [
    "print(\"X embeddings shapes:\")\n",
    "print(f'   • X train shape: {np.shape(X_train_emb)}')\n",
    "print(f'   • X val shape: {np.shape(X_val_emb)}')\n",
    "print(f'   • X test shape: {np.shape(X_test_emb)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_ovr = OneVsRestClassifier(estimator=LinearSVC(penalty='l2',\n",
    "                                                  loss='squared_hinge',\n",
    "                                                  dual='auto',\n",
    "                                                  C=1e3,\n",
    "                                                  multi_class='ovr',\n",
    "                                                  #class_weight=tag_distr_formated,\n",
    "                                                  random_state=42),\n",
    "                              n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isfile(save_models_path + 'rubert.joblib'):\n",
    "    clf_ovr = load(save_models_path + 'rubert.joblib')\n",
    "else:\n",
    "    clf_ovr.fit(X_train_emb, y_train)\n",
    "    dump(clf_ovr, save_models_path + 'rubert.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "rubert_y_pred_val = clf_ovr.predict(X_val_emb)\n",
    "\n",
    "rubert_df_val = data_val.copy()\n",
    "rubert_df_val['predicted_tags'] = Vec.inverse_transform(rubert_y_pred_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text_markdown</th>\n",
       "      <th>tags</th>\n",
       "      <th>predicted_tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>421</th>\n",
       "      <td>6992880</td>\n",
       "      <td>[популярный, пк, игра, создавать, устройство, проходить, картинка, память, оставаться, различный, создавать, написать, догадка...</td>\n",
       "      <td>[помогите найти]</td>\n",
       "      <td>[игры]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432</th>\n",
       "      <td>6992917</td>\n",
       "      <td>[профессия, оказываться, сопровождать, образование, курсы, обязанность, входить, хотеться, разговор, зажигать, свеча, оказыват...</td>\n",
       "      <td>[психология]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>578</th>\n",
       "      <td>6994231</td>\n",
       "      <td>[предыдущий, пост, бригада, график, переписывать, месяц, дата, окончание, поездка, графика, случаться, называть, двойной, поез...</td>\n",
       "      <td>[юмор, реальная история из жизни]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>591</th>\n",
       "      <td>6992488</td>\n",
       "      <td>[широкий, хотеться, обращать, внимание, инцидент, связанный, дтп, участие, пожарный, двигаться, оперативный, вызов, включать, ...</td>\n",
       "      <td>[помощь]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>807</th>\n",
       "      <td>7021892</td>\n",
       "      <td>[история, скоро, девушка, упасть, дерево, парень, неловко, улыбаться, следовать, забывать, следить, окружение, темно, отзывать...</td>\n",
       "      <td>[рассказ, фантастика, мат]</td>\n",
       "      <td>[авторский рассказ, рассказ]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  \\\n",
       "421  6992880   \n",
       "432  6992917   \n",
       "578  6994231   \n",
       "591  6992488   \n",
       "807  7021892   \n",
       "\n",
       "                                                                                                                         text_markdown  \\\n",
       "421  [популярный, пк, игра, создавать, устройство, проходить, картинка, память, оставаться, различный, создавать, написать, догадка...   \n",
       "432  [профессия, оказываться, сопровождать, образование, курсы, обязанность, входить, хотеться, разговор, зажигать, свеча, оказыват...   \n",
       "578  [предыдущий, пост, бригада, график, переписывать, месяц, дата, окончание, поездка, графика, случаться, называть, двойной, поез...   \n",
       "591  [широкий, хотеться, обращать, внимание, инцидент, связанный, дтп, участие, пожарный, двигаться, оперативный, вызов, включать, ...   \n",
       "807  [история, скоро, девушка, упасть, дерево, парень, неловко, улыбаться, следовать, забывать, следить, окружение, темно, отзывать...   \n",
       "\n",
       "                                  tags                predicted_tags  \n",
       "421                   [помогите найти]                        [игры]  \n",
       "432                       [психология]                            []  \n",
       "578  [юмор, реальная история из жизни]                            []  \n",
       "591                           [помощь]                            []  \n",
       "807         [рассказ, фантастика, мат]  [авторский рассказ, рассказ]  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rubert_df_val.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for rubert embeddings:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.35      0.28      0.31        25\n",
      "           1       0.20      0.02      0.04        45\n",
      "           2       1.00      0.05      0.10        40\n",
      "           3       0.75      0.11      0.19        27\n",
      "           4       0.45      0.19      0.26        27\n",
      "           5       0.00      0.00      0.00        68\n",
      "           6       0.50      0.07      0.13        40\n",
      "           7       0.25      0.02      0.03        59\n",
      "           8       1.00      0.05      0.09        42\n",
      "           9       0.58      0.16      0.25       113\n",
      "          10       0.75      0.06      0.11        50\n",
      "          11       0.00      0.00      0.00        85\n",
      "          12       0.00      0.00      0.00        72\n",
      "          13       0.68      0.40      0.50        58\n",
      "          14       0.00      0.00      0.00        52\n",
      "          15       0.00      0.00      0.00        28\n",
      "          16       0.00      0.00      0.00       135\n",
      "          17       0.63      0.52      0.57        23\n",
      "          18       0.54      0.56      0.55        25\n",
      "          19       0.40      0.08      0.13        50\n",
      "          20       0.33      0.14      0.20        29\n",
      "          21       0.79      0.57      0.66       164\n",
      "          22       0.92      0.49      0.64        45\n",
      "          23       0.00      0.00      0.00        77\n",
      "          24       0.36      0.16      0.22        32\n",
      "          25       0.67      0.04      0.08        47\n",
      "          26       0.00      0.00      0.00        25\n",
      "          27       0.74      0.06      0.12       218\n",
      "          28       0.33      0.06      0.11        48\n",
      "          29       0.00      0.00      0.00        39\n",
      "          30       0.54      0.34      0.42        38\n",
      "          31       0.00      0.00      0.00        38\n",
      "          32       1.00      0.02      0.04        53\n",
      "          33       0.81      0.23      0.36        57\n",
      "          34       0.68      0.26      0.38        57\n",
      "          35       0.00      0.00      0.00       102\n",
      "          36       1.00      0.04      0.09        90\n",
      "          37       0.00      0.00      0.00        23\n",
      "          38       0.71      0.26      0.39       136\n",
      "          39       0.36      0.11      0.17        45\n",
      "          40       0.68      0.22      0.34       243\n",
      "          41       1.00      0.16      0.28        49\n",
      "          42       0.77      0.24      0.36       113\n",
      "          43       0.57      0.12      0.20       133\n",
      "          44       0.00      0.00      0.00       118\n",
      "          45       0.00      0.00      0.00        31\n",
      "          46       0.75      0.03      0.06       105\n",
      "          47       1.00      0.07      0.13        29\n",
      "          48       0.00      0.00      0.00        29\n",
      "          49       0.50      0.01      0.03        68\n",
      "          50       0.00      0.00      0.00        47\n",
      "          51       0.00      0.00      0.00        22\n",
      "          52       0.56      0.14      0.22        36\n",
      "          53       0.27      0.10      0.15        29\n",
      "          54       0.76      0.64      0.69       116\n",
      "          55       0.81      0.53      0.64        99\n",
      "          56       0.88      0.15      0.26        46\n",
      "          57       0.52      0.32      0.39        38\n",
      "          58       0.70      0.40      0.51        53\n",
      "          59       0.00      0.00      0.00       160\n",
      "\n",
      "   micro avg       0.67      0.15      0.25      3991\n",
      "   macro avg       0.45      0.14      0.19      3991\n",
      "weighted avg       0.48      0.15      0.21      3991\n",
      " samples avg       0.20      0.16      0.17      3991\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Metrics for rubert embeddings:')\n",
    "print(classification_report(y_val, rubert_y_pred_val, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate `recall@k`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean recall@k for k=5 for model with rubert embeddings: 0.163\n"
     ]
    }
   ],
   "source": [
    "rubert_recallk_mean, rubert_recallk_med = recallk(rubert_df_val.tags, rubert_df_val.predicted_tags, k=K)\n",
    "\n",
    "print(f'Mean recall@k for k={K} for model with rubert embeddings: {rubert_recallk_mean:.3f}')\n",
    "#print(f'Median recall@k for k={K} for model with rubert embeddings:: {rubert_recallk_med:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 3. Results\n",
    "\n",
    "As the result of training with different embeddings, we have the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean recall@k's for SVM with k = 5:\n",
      "\n",
      "  • Recall@k for Bag-of-Words: 0.3080\n",
      "  • Recall@k for TF-IDF: 0.2990\n",
      "  • Recall@k for rubert embeddings: 0.1625\n"
     ]
    }
   ],
   "source": [
    "print(f\"Mean recall@k's for SVM with k = {K}:\\n\")\n",
    "print(f'  • Recall@k for Bag-of-Words: {bow_recallk_mean:.4f}')\n",
    "print(f'  • Recall@k for TF-IDF: {tf_idf_recallk_mean:.4f}')\n",
    "print(f'  • Recall@k for rubert embeddings: {rubert_recallk_mean:.4f}')\n",
    "\n",
    "#print(f\"\\nMedian recall@k's for SVM with k = {K}:\\n\")\n",
    "#print(f'  • Recall@k for Bag-of-Words: {bow_recallk_med:3f}')\n",
    "#print(f'  • Recall@k for TF-IDF: {tf_idf_recallk_med:3f}')\n",
    "#print(f'  • Recall@k for rubert embeddings: {rubert_recallk_med:3f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
