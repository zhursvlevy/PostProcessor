{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression for topic classification\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "module_path = os.path.abspath(os.path.join('..\\..')) # Path to root folder\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path + \"/scripts\") # define scripts path\n",
    "\n",
    "from ipynb_func import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data loader:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NUM = 10 # Number of data parquets to use\n",
    "#assert NUM >= 1 and NUM <= 10, \"NUM value must be in range [1, 10]\"\n",
    "\n",
    "# Making list of roots to merge processed raw data \n",
    "#paths = [module_path + f\"/data/pikabu/tag_processed/raw_data/{i}_tag_processed.parquet\" for i in range(NUM)] \n",
    "\n",
    "# Making list of roots to merge processed filtered data\n",
    "#paths = [module_path + f\"/data/pikabu/tag_processed/filtered_data/{i}_tag_processed.parquet\" for i in range(NUM)] \n",
    "\n",
    "# Making list of roots to merge processed cleared data\n",
    "paths = [module_path + f\"/data/pikabu/splited_data/cleared_texts.parquet\"] \n",
    "\n",
    "data = merge_dataset(paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text_markdown</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>6991359</td>\n",
       "      <td>[добрый, сутки, господин, дама, подсказывать, название, игра, телефон, оформление, убийство, зомби, очки, ездить, машинка, крутить, развивать, скорость, заранее, благодарить]</td>\n",
       "      <td>[игры, поиск]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>7004423</td>\n",
       "      <td>[ехать, девчонка, школа, оставаться, свободный, макс, заявка, прямой, конечный, адрес, железнодорожный, институт, включать, вбивать, адрес, выдавать, столовая, ладно, садиться,...</td>\n",
       "      <td>[юмор]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>6991603</td>\n",
       "      <td>[стадо, стадо, гигантский, случаться, стадо, управлять, волк, предел, волк, жопа, враг, дружно, осматривать, выдавливать, стадо, выдавливать, съедать, волк, близкий, холм, обхо...</td>\n",
       "      <td>[мат]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  \\\n",
       "15  6991359   \n",
       "37  7004423   \n",
       "52  6991603   \n",
       "\n",
       "                                                                                                                                                                          text_markdown  \\\n",
       "15       [добрый, сутки, господин, дама, подсказывать, название, игра, телефон, оформление, убийство, зомби, очки, ездить, машинка, крутить, развивать, скорость, заранее, благодарить]   \n",
       "37  [ехать, девчонка, школа, оставаться, свободный, макс, заявка, прямой, конечный, адрес, железнодорожный, институт, включать, вбивать, адрес, выдавать, столовая, ладно, садиться,...   \n",
       "52  [стадо, стадо, гигантский, случаться, стадо, управлять, волк, предел, волк, жопа, враг, дружно, осматривать, выдавливать, стадо, выдавливать, съедать, волк, близкий, холм, обхо...   \n",
       "\n",
       "             tags  \n",
       "15  [игры, поиск]  \n",
       "37         [юмор]  \n",
       "52          [мат]  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', 180)\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 1. Data preparation and split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(module_path + f\"/data/pikabu/splited_data/indexes.json\") as f:\n",
    "    id_splits = f.read()\n",
    "\n",
    "id_splits = json.loads(id_splits)\n",
    "\n",
    "data_train = data[data['id'].isin(id_splits['train'])]\n",
    "data_val = data[data['id'].isin(id_splits['val'])]\n",
    "data_test = data[data['id'].isin(id_splits['test'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train data: 25209\n",
      "Number of val data: 2821\n",
      "Number of test data: 3119\n",
      "Distribution: 81 / 9 / 10\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of train data: {len(data_train)}\")\n",
    "print(f\"Number of val data: {len(data_val)}\")\n",
    "print(f\"Number of test data: {len(data_test)}\")\n",
    "print(f\"Distribution: {len(data_train)/len(data)*100:.0f} / {len(data_val)/len(data)*100:.0f} / {len(data_test)/len(data)*100:.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 2. Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from joblib import dump, load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Target preparation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\decique\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "Vec = CountVectorizer(tokenizer=lambda x: x.split(','), binary=True)\n",
    "\n",
    "df = data.copy()\n",
    "df.tags = [','.join(i) for i in df.tags]\n",
    "\n",
    "df_train = data_train.copy()\n",
    "df_train.tags = [','.join(i) for i in df_train.tags]\n",
    "\n",
    "df_val = data_val.copy()\n",
    "df_val.tags = [','.join(i) for i in df_val.tags]\n",
    "\n",
    "df_test = data_test.copy()\n",
    "df_test.tags = [','.join(i) for i in df_test.tags]\n",
    "\n",
    "y_data = Vec.fit(df['tags'])\n",
    "y_train = Vec.transform(df_train['tags'])\n",
    "y_val = Vec.transform(df_val['tags'])\n",
    "y_test = Vec.transform(df_test['tags'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tags to predict:\n",
      "['авто' 'авторский рассказ' 'алкоголь' 'анекдот' 'армия' 'вопрос' 'врачи'\n",
      " 'девушки' 'деньги' 'дети' 'детство' 'другое' 'жизнь' 'игры' 'интересное'\n",
      " 'истории' 'история' 'ищу книгу' 'ищу фильм' 'карантин' 'книги'\n",
      " 'коронавирус' 'кот' 'лига добра' 'лига юристов' 'любовь' 'люди' 'мат'\n",
      " 'медицина' 'москва' 'музыка' 'мысли' 'негатив' 'новости' 'новый год'\n",
      " 'общество' 'отношения' 'поиск' 'политика' 'помогите найти' 'помощь'\n",
      " 'психология' 'работа' 'рассказ' 'реальная история из жизни'\n",
      " 'родители и дети' 'россия' 'самоизоляция' 'санкт-петербург' 'семья'\n",
      " 'случай из жизни' 'совет' 'сон' 'соседи' 'стихи' 'украина' 'фантастика'\n",
      " 'фильмы' 'школа' 'юмор']\n"
     ]
    }
   ],
   "source": [
    "print('Tags to predict:')\n",
    "print(Vec.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_distr = getworddict(getwordlist(data.tags))\n",
    "tag_distr_formated = {}\n",
    "for i in range(len(tag_distr)):\n",
    "    tag_distr_formated[i] = round(tag_distr[Vec.get_feature_names_out()[i]] / sum(tag_distr.values()), 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tags weights:\n",
      "{0: 0.0073, 1: 0.0121, 2: 0.0075, 3: 0.0079, 4: 0.0085, 5: 0.0196, 6: 0.0077, 7: 0.0138, 8: 0.0089, 9: 0.0279, 10: 0.011, 11: 0.0221, 12: 0.0186, 13: 0.0122, 14: 0.0122, 15: 0.0086, 16: 0.0338, 17: 0.0067, 18: 0.008, 19: 0.014, 20: 0.0107, 21: 0.0454, 22: 0.0121, 23: 0.0142, 24: 0.0078, 25: 0.0149, 26: 0.0084, 27: 0.0549, 28: 0.0125, 29: 0.0098, 30: 0.0081, 31: 0.0093, 32: 0.0145, 33: 0.0152, 34: 0.0133, 35: 0.0237, 36: 0.0206, 37: 0.0071, 38: 0.0308, 39: 0.0118, 40: 0.054, 41: 0.0121, 42: 0.0297, 43: 0.0303, 44: 0.0315, 45: 0.0082, 46: 0.0277, 47: 0.0063, 48: 0.0075, 49: 0.0145, 50: 0.0122, 51: 0.0078, 52: 0.0067, 53: 0.0086, 54: 0.0274, 55: 0.0275, 56: 0.0111, 57: 0.0104, 58: 0.0144, 59: 0.0384}\n"
     ]
    }
   ],
   "source": [
    "print('Tags weights:')\n",
    "print(tag_distr_formated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y shapes:\n",
      "  • Y train: (25209, 60)\n",
      "  • Y validation: (2821, 60)\n",
      "  • Y test: (3119, 60)\n"
     ]
    }
   ],
   "source": [
    "print('Y shapes:')\n",
    "print(f'  • Y train: {y_train.shape}')\n",
    "print(f'  • Y validation: {y_val.shape}')\n",
    "print(f'  • Y test: {y_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Training with bag-of-words embeddings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_models_path = module_path + '/models/logreg/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data = [' '.join(txt) for txt in data.text_markdown]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = [' '.join(txt) for txt in data_train.text_markdown]\n",
    "X_val = [' '.join(txt) for txt in data_val.text_markdown]\n",
    "X_test = [' '.join(txt) for txt in data_test.text_markdown]\n",
    "\n",
    "X_Vec = CountVectorizer(tokenizer = lambda x: x.split())\n",
    "\n",
    "X_Vec.fit(X_train)\n",
    "X_train = X_Vec.transform(X_train)\n",
    "X_test = X_Vec.transform(X_test)\n",
    "X_val = X_Vec.transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X BoW's shapes:\n",
      "   • X train shape: (25209, 5899)\n",
      "   • X val shape: (2821, 5899)\n",
      "   • X test shape: (3119, 5899)\n"
     ]
    }
   ],
   "source": [
    "print(\"X BoW's shapes:\")\n",
    "print(f'   • X train shape: {X_train.shape}')\n",
    "print(f'   • X val shape: {X_val.shape}')\n",
    "print(f'   • X test shape: {X_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "# Searching for best model params; too long;\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "LogReg_cfg = {'estimator__C':[1e3, 1e5, 1e7, 1e8],\n",
    "              'estimator__penalty': ['elasticnet', 'l1', 'l2'],\n",
    "              'estimator__dual': [False],\n",
    "              'estimator__class_weight': [None, tag_distr_formated],\n",
    "              'estimator__solver': ['lbfgs', 'liblinear', 'newton-cg'],\n",
    "              'estimator__random_state': [42]}\n",
    "\n",
    "clf_ovr = OneVsRestClassifier(estimator=LogisticRegression(),\n",
    "                              n_jobs=-1)\n",
    "\n",
    "GSCV_clf = GridSearchCV(estimator=clf_ovr, param_grid=LogReg_cfg)\n",
    "\n",
    "GSCV_clf.fit(X_train, y_train)\n",
    "\n",
    "GSCV_clf.best_params_ \n",
    "\n",
    "\"\"\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "LogReg_cfg = {'C':5e7,\n",
    "              'penalty': 'l2',\n",
    "              'dual': False,\n",
    "              'class_weight': tag_distr_formated,\n",
    "              'solver': 'liblinear',\n",
    "              'random_state': 42}\n",
    "\n",
    "clf_ovr = OneVsRestClassifier(estimator=LogisticRegression(C=LogReg_cfg['C'],\n",
    "                                                           dual=LogReg_cfg['dual'],\n",
    "                                                           class_weight=LogReg_cfg['class_weight'],\n",
    "                                                           penalty=LogReg_cfg['penalty'],\n",
    "                                                           solver=LogReg_cfg['solver'],\n",
    "                                                           random_state=LogReg_cfg['random_state']),\n",
    "                              n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isfile(save_models_path + 'bow.joblib'):\n",
    "    clf_ovr = load(save_models_path + 'bow.joblib')\n",
    "else:\n",
    "    clf_ovr.fit(X_train, y_train)\n",
    "    dump(clf_ovr, save_models_path + 'bow.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_y_pred_val = clf_ovr.predict(X_val)\n",
    "bow_y_probas = clf_ovr.predict_proba(X_val)\n",
    "bow_y_labels = sorted_labels(bow_y_pred_val, bow_y_probas, Vec)\n",
    "\n",
    "bow_df_val = data_val.copy()\n",
    "bow_df_val['predicted_tags'] = bow_y_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text_markdown</th>\n",
       "      <th>tags</th>\n",
       "      <th>predicted_tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>421</th>\n",
       "      <td>6992880</td>\n",
       "      <td>[популярный, пк, игра, создавать, устройство, проходить, картинка, память, оставаться, различный, создавать, написать, догадка, дикий, желание, проходить]</td>\n",
       "      <td>[помогите найти]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432</th>\n",
       "      <td>6992917</td>\n",
       "      <td>[профессия, оказываться, сопровождать, образование, курсы, обязанность, входить, хотеться, разговор, зажигать, свеча, оказываться, нарушение, род, кодекс, общий, тысяча, цена, ...</td>\n",
       "      <td>[психология]</td>\n",
       "      <td>[работа]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>578</th>\n",
       "      <td>6994231</td>\n",
       "      <td>[предыдущий, пост, бригада, график, переписывать, месяц, дата, окончание, поездка, графика, случаться, называть, двойной, поездка, бригада, происходить, ошибка, редко, ситуация...</td>\n",
       "      <td>[юмор, реальная история из жизни]</td>\n",
       "      <td>[мат]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>591</th>\n",
       "      <td>6992488</td>\n",
       "      <td>[широкий, хотеться, обращать, внимание, инцидент, связанный, дтп, участие, пожарный, двигаться, оперативный, вызов, включать, сигнал, легко, заводить, уголовный, водитель, факт...</td>\n",
       "      <td>[помощь]</td>\n",
       "      <td>[новости]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>807</th>\n",
       "      <td>7021892</td>\n",
       "      <td>[история, скоро, девушка, упасть, дерево, парень, неловко, улыбаться, следовать, забывать, следить, окружение, темно, отзываться, слегка, восклицать, показывать, парень, старат...</td>\n",
       "      <td>[рассказ, фантастика, мат]</td>\n",
       "      <td>[авторский рассказ, рассказ, фантастика, история]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  \\\n",
       "421  6992880   \n",
       "432  6992917   \n",
       "578  6994231   \n",
       "591  6992488   \n",
       "807  7021892   \n",
       "\n",
       "                                                                                                                                                                           text_markdown  \\\n",
       "421                           [популярный, пк, игра, создавать, устройство, проходить, картинка, память, оставаться, различный, создавать, написать, догадка, дикий, желание, проходить]   \n",
       "432  [профессия, оказываться, сопровождать, образование, курсы, обязанность, входить, хотеться, разговор, зажигать, свеча, оказываться, нарушение, род, кодекс, общий, тысяча, цена, ...   \n",
       "578  [предыдущий, пост, бригада, график, переписывать, месяц, дата, окончание, поездка, графика, случаться, называть, двойной, поездка, бригада, происходить, ошибка, редко, ситуация...   \n",
       "591  [широкий, хотеться, обращать, внимание, инцидент, связанный, дтп, участие, пожарный, двигаться, оперативный, вызов, включать, сигнал, легко, заводить, уголовный, водитель, факт...   \n",
       "807  [история, скоро, девушка, упасть, дерево, парень, неловко, улыбаться, следовать, забывать, следить, окружение, темно, отзываться, слегка, восклицать, показывать, парень, старат...   \n",
       "\n",
       "                                  tags  \\\n",
       "421                   [помогите найти]   \n",
       "432                       [психология]   \n",
       "578  [юмор, реальная история из жизни]   \n",
       "591                           [помощь]   \n",
       "807         [рассказ, фантастика, мат]   \n",
       "\n",
       "                                        predicted_tags  \n",
       "421                                                 []  \n",
       "432                                           [работа]  \n",
       "578                                              [мат]  \n",
       "591                                          [новости]  \n",
       "807  [авторский рассказ, рассказ, фантастика, история]  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_df_val.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for Bag-of-Words:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.28      0.30        25\n",
      "           1       0.26      0.22      0.24        45\n",
      "           2       0.48      0.30      0.37        40\n",
      "           3       0.23      0.26      0.24        27\n",
      "           4       0.46      0.44      0.45        27\n",
      "           5       0.09      0.13      0.10        68\n",
      "           6       0.43      0.33      0.37        40\n",
      "           7       0.23      0.27      0.25        59\n",
      "           8       0.10      0.10      0.10        42\n",
      "           9       0.24      0.32      0.28       113\n",
      "          10       0.25      0.26      0.26        50\n",
      "          11       0.04      0.05      0.05        85\n",
      "          12       0.06      0.10      0.08        72\n",
      "          13       0.51      0.52      0.51        58\n",
      "          14       0.02      0.02      0.02        52\n",
      "          15       0.03      0.04      0.03        28\n",
      "          16       0.13      0.16      0.14       135\n",
      "          17       0.40      0.35      0.37        23\n",
      "          18       0.31      0.44      0.36        25\n",
      "          19       0.23      0.26      0.24        50\n",
      "          20       0.22      0.24      0.23        29\n",
      "          21       0.71      0.70      0.70       164\n",
      "          22       0.61      0.42      0.50        45\n",
      "          23       0.28      0.23      0.26        77\n",
      "          24       0.47      0.44      0.45        32\n",
      "          25       0.16      0.28      0.21        47\n",
      "          26       0.02      0.04      0.03        25\n",
      "          27       0.32      0.39      0.35       218\n",
      "          28       0.30      0.33      0.32        48\n",
      "          29       0.12      0.15      0.13        39\n",
      "          30       0.41      0.39      0.40        38\n",
      "          31       0.12      0.08      0.10        38\n",
      "          32       0.14      0.15      0.14        53\n",
      "          33       0.31      0.28      0.29        57\n",
      "          34       0.50      0.53      0.51        57\n",
      "          35       0.09      0.10      0.09       102\n",
      "          36       0.24      0.26      0.25        90\n",
      "          37       0.05      0.04      0.04        23\n",
      "          38       0.44      0.36      0.40       136\n",
      "          39       0.12      0.13      0.12        45\n",
      "          40       0.41      0.42      0.41       243\n",
      "          41       0.32      0.31      0.31        49\n",
      "          42       0.30      0.39      0.34       113\n",
      "          43       0.31      0.29      0.30       133\n",
      "          44       0.14      0.18      0.15       118\n",
      "          45       0.12      0.16      0.14        31\n",
      "          46       0.21      0.19      0.20       105\n",
      "          47       0.19      0.14      0.16        29\n",
      "          48       0.16      0.14      0.15        29\n",
      "          49       0.25      0.24      0.24        68\n",
      "          50       0.02      0.02      0.02        47\n",
      "          51       0.02      0.05      0.03        22\n",
      "          52       0.40      0.22      0.29        36\n",
      "          53       0.38      0.34      0.36        29\n",
      "          54       0.57      0.54      0.56       116\n",
      "          55       0.66      0.59      0.62        99\n",
      "          56       0.36      0.30      0.33        46\n",
      "          57       0.49      0.47      0.48        38\n",
      "          58       0.51      0.43      0.47        53\n",
      "          59       0.17      0.19      0.18       160\n",
      "\n",
      "   micro avg       0.28      0.30      0.29      3991\n",
      "   macro avg       0.27      0.27      0.27      3991\n",
      "weighted avg       0.30      0.30      0.29      3991\n",
      " samples avg       0.25      0.30      0.25      3991\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Metrics for Bag-of-Words:')\n",
    "print(classification_report(y_val, bow_y_pred_val, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate `recall@k`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean recall@k for k=5 for Bag-of-Words: 0.304\n"
     ]
    }
   ],
   "source": [
    "K = 5\n",
    "bow_recallk_mean, bow_recallk_med = recallk(bow_df_val.tags, bow_df_val.predicted_tags, k=K)\n",
    "\n",
    "print(f'Mean recall@k for k={K} for Bag-of-Words: {bow_recallk_mean:.3f}')\n",
    "#print(f'Median recall@k for k={K} for Bag-of-Words: {bow_recallk_med:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Training with IF-IDF embeddings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\decique\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "X_train = [' '.join(txt) for txt in data_train.text_markdown]\n",
    "X_val = [' '.join(txt) for txt in data_val.text_markdown]\n",
    "X_test = [' '.join(txt) for txt in data_test.text_markdown]\n",
    "\n",
    "Tfidf_Vec = TfidfVectorizer(tokenizer = lambda x: x.split())\n",
    "\n",
    "Tfidf_Vec.fit(X_train)\n",
    "X_train = Tfidf_Vec.transform(X_train)\n",
    "X_test = Tfidf_Vec.transform(X_test)\n",
    "X_val = Tfidf_Vec.transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X TF-IDF's shapes:\n",
      "   • X train shape: (25209, 5899)\n",
      "   • X val shape: (2821, 5899)\n",
      "   • X test shape: (3119, 5899)\n"
     ]
    }
   ],
   "source": [
    "print(\"X TF-IDF's shapes:\")\n",
    "print(f'   • X train shape: {X_train.shape}')\n",
    "print(f'   • X val shape: {X_val.shape}')\n",
    "print(f'   • X test shape: {X_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "LogReg_cfg = {'C':5e7,\n",
    "              'penalty': 'l2',\n",
    "              'dual': False,\n",
    "              'class_weight': tag_distr_formated,\n",
    "              'solver': 'liblinear',\n",
    "              'random_state': 42}\n",
    "\n",
    "clf_ovr = OneVsRestClassifier(estimator=LogisticRegression(C=LogReg_cfg['C'],\n",
    "                                                           dual=LogReg_cfg['dual'],\n",
    "                                                           class_weight=LogReg_cfg['class_weight'],\n",
    "                                                           penalty=LogReg_cfg['penalty'],\n",
    "                                                           solver=LogReg_cfg['solver'],\n",
    "                                                           random_state=LogReg_cfg['random_state']),\n",
    "                              n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isfile(save_models_path + 'tf_idf.joblib'):\n",
    "    clf_ovr = load(save_models_path + 'tf_idf.joblib')\n",
    "else:\n",
    "    clf_ovr.fit(X_train, y_train)\n",
    "    dump(clf_ovr, save_models_path + 'tf_idf.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_y_pred_val = clf_ovr.predict(X_val)\n",
    "tf_idf_y_probas = clf_ovr.predict_proba(X_val)\n",
    "tf_idf_y_labels = sorted_labels(tf_idf_y_pred_val, tf_idf_y_probas, Vec)\n",
    "\n",
    "tf_idf_df_val = data_val.copy()\n",
    "tf_idf_df_val['predicted_tags'] = tf_idf_y_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text_markdown</th>\n",
       "      <th>tags</th>\n",
       "      <th>predicted_tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>421</th>\n",
       "      <td>6992880</td>\n",
       "      <td>[популярный, пк, игра, создавать, устройство, проходить, картинка, память, оставаться, различный, создавать, написать, догадка, дикий, желание, проходить]</td>\n",
       "      <td>[помогите найти]</td>\n",
       "      <td>[интересное, помогите найти]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432</th>\n",
       "      <td>6992917</td>\n",
       "      <td>[профессия, оказываться, сопровождать, образование, курсы, обязанность, входить, хотеться, разговор, зажигать, свеча, оказываться, нарушение, род, кодекс, общий, тысяча, цена, ...</td>\n",
       "      <td>[психология]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>578</th>\n",
       "      <td>6994231</td>\n",
       "      <td>[предыдущий, пост, бригада, график, переписывать, месяц, дата, окончание, поездка, графика, случаться, называть, двойной, поездка, бригада, происходить, ошибка, редко, ситуация...</td>\n",
       "      <td>[юмор, реальная история из жизни]</td>\n",
       "      <td>[мат]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>591</th>\n",
       "      <td>6992488</td>\n",
       "      <td>[широкий, хотеться, обращать, внимание, инцидент, связанный, дтп, участие, пожарный, двигаться, оперативный, вызов, включать, сигнал, легко, заводить, уголовный, водитель, факт...</td>\n",
       "      <td>[помощь]</td>\n",
       "      <td>[новости, лига юристов]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>807</th>\n",
       "      <td>7021892</td>\n",
       "      <td>[история, скоро, девушка, упасть, дерево, парень, неловко, улыбаться, следовать, забывать, следить, окружение, темно, отзываться, слегка, восклицать, показывать, парень, старат...</td>\n",
       "      <td>[рассказ, фантастика, мат]</td>\n",
       "      <td>[рассказ, фантастика, авторский рассказ, история]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  \\\n",
       "421  6992880   \n",
       "432  6992917   \n",
       "578  6994231   \n",
       "591  6992488   \n",
       "807  7021892   \n",
       "\n",
       "                                                                                                                                                                           text_markdown  \\\n",
       "421                           [популярный, пк, игра, создавать, устройство, проходить, картинка, память, оставаться, различный, создавать, написать, догадка, дикий, желание, проходить]   \n",
       "432  [профессия, оказываться, сопровождать, образование, курсы, обязанность, входить, хотеться, разговор, зажигать, свеча, оказываться, нарушение, род, кодекс, общий, тысяча, цена, ...   \n",
       "578  [предыдущий, пост, бригада, график, переписывать, месяц, дата, окончание, поездка, графика, случаться, называть, двойной, поездка, бригада, происходить, ошибка, редко, ситуация...   \n",
       "591  [широкий, хотеться, обращать, внимание, инцидент, связанный, дтп, участие, пожарный, двигаться, оперативный, вызов, включать, сигнал, легко, заводить, уголовный, водитель, факт...   \n",
       "807  [история, скоро, девушка, упасть, дерево, парень, неловко, улыбаться, следовать, забывать, следить, окружение, темно, отзываться, слегка, восклицать, показывать, парень, старат...   \n",
       "\n",
       "                                  tags  \\\n",
       "421                   [помогите найти]   \n",
       "432                       [психология]   \n",
       "578  [юмор, реальная история из жизни]   \n",
       "591                           [помощь]   \n",
       "807         [рассказ, фантастика, мат]   \n",
       "\n",
       "                                        predicted_tags  \n",
       "421                       [интересное, помогите найти]  \n",
       "432                                                 []  \n",
       "578                                              [мат]  \n",
       "591                            [новости, лига юристов]  \n",
       "807  [рассказ, фантастика, авторский рассказ, история]  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf_df_val.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for TF-IDF:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.24      0.31        25\n",
      "           1       0.32      0.24      0.28        45\n",
      "           2       0.68      0.33      0.44        40\n",
      "           3       0.41      0.26      0.32        27\n",
      "           4       0.55      0.44      0.49        27\n",
      "           5       0.12      0.13      0.13        68\n",
      "           6       0.52      0.28      0.36        40\n",
      "           7       0.28      0.25      0.27        59\n",
      "           8       0.09      0.05      0.06        42\n",
      "           9       0.31      0.35      0.33       113\n",
      "          10       0.33      0.20      0.25        50\n",
      "          11       0.03      0.05      0.04        85\n",
      "          12       0.10      0.14      0.12        72\n",
      "          13       0.63      0.47      0.53        58\n",
      "          14       0.03      0.02      0.02        52\n",
      "          15       0.00      0.00      0.00        28\n",
      "          16       0.13      0.17      0.15       135\n",
      "          17       0.64      0.30      0.41        23\n",
      "          18       0.56      0.40      0.47        25\n",
      "          19       0.34      0.28      0.31        50\n",
      "          20       0.33      0.21      0.26        29\n",
      "          21       0.71      0.71      0.71       164\n",
      "          22       0.79      0.42      0.55        45\n",
      "          23       0.35      0.27      0.31        77\n",
      "          24       0.38      0.31      0.34        32\n",
      "          25       0.18      0.19      0.19        47\n",
      "          26       0.05      0.04      0.05        25\n",
      "          27       0.29      0.38      0.33       218\n",
      "          28       0.38      0.25      0.30        48\n",
      "          29       0.20      0.13      0.16        39\n",
      "          30       0.58      0.39      0.47        38\n",
      "          31       0.27      0.08      0.12        38\n",
      "          32       0.19      0.15      0.17        53\n",
      "          33       0.26      0.21      0.23        57\n",
      "          34       0.62      0.49      0.55        57\n",
      "          35       0.12      0.16      0.14       102\n",
      "          36       0.31      0.28      0.29        90\n",
      "          37       0.12      0.04      0.06        23\n",
      "          38       0.39      0.38      0.39       136\n",
      "          39       0.13      0.13      0.13        45\n",
      "          40       0.32      0.40      0.35       243\n",
      "          41       0.42      0.22      0.29        49\n",
      "          42       0.36      0.41      0.38       113\n",
      "          43       0.32      0.29      0.31       133\n",
      "          44       0.13      0.20      0.16       118\n",
      "          45       0.17      0.10      0.12        31\n",
      "          46       0.16      0.19      0.17       105\n",
      "          47       0.33      0.14      0.20        29\n",
      "          48       0.35      0.24      0.29        29\n",
      "          49       0.33      0.26      0.29        68\n",
      "          50       0.00      0.00      0.00        47\n",
      "          51       0.00      0.00      0.00        22\n",
      "          52       0.62      0.22      0.33        36\n",
      "          53       0.41      0.31      0.35        29\n",
      "          54       0.63      0.53      0.58       116\n",
      "          55       0.66      0.61      0.63        99\n",
      "          56       0.59      0.28      0.38        46\n",
      "          57       0.54      0.39      0.45        38\n",
      "          58       0.56      0.42      0.48        53\n",
      "          59       0.14      0.19      0.16       160\n",
      "\n",
      "   micro avg       0.31      0.29      0.30      3991\n",
      "   macro avg       0.34      0.25      0.28      3991\n",
      "weighted avg       0.33      0.29      0.30      3991\n",
      " samples avg       0.25      0.30      0.25      3991\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Metrics for TF-IDF:')\n",
    "print(classification_report(y_val, tf_idf_y_pred_val, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate `recall@k`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean recall@k for k=5 for TF-IDF: 0.297\n"
     ]
    }
   ],
   "source": [
    "tf_idf_recallk_mean, tf_idf_recallk_med = recallk(tf_idf_df_val.tags, tf_idf_df_val.predicted_tags, k=K)\n",
    "\n",
    "print(f'Mean recall@k for k={K} for TF-IDF: {tf_idf_recallk_mean:.3f}')\n",
    "#print(f'Median recall@k for k={K} for TF-IDF: {tf_idf_recallk_med:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3. Training on TF-IDF with N-grams:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\decique\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "X_train = [' '.join(txt) for txt in data_train.text_markdown]\n",
    "X_val = [' '.join(txt) for txt in data_val.text_markdown]\n",
    "X_test = [' '.join(txt) for txt in data_test.text_markdown]\n",
    "\n",
    "Tfidf_Vec = TfidfVectorizer(tokenizer = lambda x: x.split(), ngram_range=(1, 2))\n",
    "\n",
    "Tfidf_Vec.fit(X_train)\n",
    "X_train = Tfidf_Vec.transform(X_train)\n",
    "X_test = Tfidf_Vec.transform(X_test)\n",
    "X_val = Tfidf_Vec.transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X TF-IDF with n-grams's shapes:\n",
      "   • X train shape: (25209, 1654803)\n",
      "   • X val shape: (2821, 1654803)\n",
      "   • X test shape: (3119, 1654803)\n"
     ]
    }
   ],
   "source": [
    "print(\"X TF-IDF with n-grams's shapes:\")\n",
    "print(f'   • X train shape: {X_train.shape}')\n",
    "print(f'   • X val shape: {X_val.shape}')\n",
    "print(f'   • X test shape: {X_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "LogReg_cfg = {'C':1e8,\n",
    "              'penalty': 'l2',\n",
    "              'dual': False,\n",
    "              'class_weight': tag_distr_formated,\n",
    "              'solver': 'lbfgs',\n",
    "              'random_state': 42}\n",
    "\n",
    "clf_ovr = OneVsRestClassifier(estimator=LogisticRegression(C=LogReg_cfg['C'],\n",
    "                                                           dual=LogReg_cfg['dual'],\n",
    "                                                           class_weight=LogReg_cfg['class_weight'],\n",
    "                                                           penalty=LogReg_cfg['penalty'],\n",
    "                                                           solver=LogReg_cfg['solver'],\n",
    "                                                           random_state=LogReg_cfg['random_state']),\n",
    "                              n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isfile(save_models_path + 'tf_idf_ngrams.joblib'):\n",
    "    clf_ovr = load(save_models_path + 'tf_idf_ngrams.joblib')\n",
    "else:\n",
    "    clf_ovr.fit(X_train, y_train)\n",
    "    dump(clf_ovr, save_models_path + 'tf_idf_ngrams.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_gram_tf_idf_y_pred_val = clf_ovr.predict(X_val)\n",
    "n_gram_tf_idf_y_probas = clf_ovr.predict_proba(X_val)\n",
    "n_gram_tf_idf_y_labels = sorted_labels(n_gram_tf_idf_y_pred_val, n_gram_tf_idf_y_probas, Vec)\n",
    "\n",
    "n_gram_tf_idf_df_val = data_val.copy()\n",
    "n_gram_tf_idf_df_val['predicted_tags'] = n_gram_tf_idf_y_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for TF-IDF with 1-2 n-grams:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.28      0.35        25\n",
      "           1       0.36      0.27      0.31        45\n",
      "           2       0.58      0.28      0.37        40\n",
      "           3       0.71      0.19      0.29        27\n",
      "           4       0.60      0.44      0.51        27\n",
      "           5       0.39      0.10      0.16        68\n",
      "           6       0.45      0.25      0.32        40\n",
      "           7       0.50      0.19      0.27        59\n",
      "           8       0.11      0.02      0.04        42\n",
      "           9       0.47      0.32      0.38       113\n",
      "          10       0.46      0.32      0.38        50\n",
      "          11       0.17      0.01      0.02        85\n",
      "          12       0.22      0.06      0.09        72\n",
      "          13       0.68      0.52      0.59        58\n",
      "          14       0.25      0.02      0.04        52\n",
      "          15       0.00      0.00      0.00        28\n",
      "          16       0.34      0.10      0.16       135\n",
      "          17       0.79      0.48      0.59        23\n",
      "          18       0.57      0.52      0.54        25\n",
      "          19       0.41      0.26      0.32        50\n",
      "          20       0.32      0.21      0.25        29\n",
      "          21       0.80      0.71      0.75       164\n",
      "          22       0.75      0.40      0.52        45\n",
      "          23       0.53      0.25      0.34        77\n",
      "          24       0.57      0.38      0.45        32\n",
      "          25       0.21      0.13      0.16        47\n",
      "          26       0.00      0.00      0.00        25\n",
      "          27       0.49      0.39      0.44       218\n",
      "          28       0.41      0.19      0.26        48\n",
      "          29       0.28      0.13      0.18        39\n",
      "          30       0.70      0.50      0.58        38\n",
      "          31       0.40      0.05      0.09        38\n",
      "          32       0.45      0.19      0.27        53\n",
      "          33       0.49      0.37      0.42        57\n",
      "          34       0.70      0.49      0.58        57\n",
      "          35       0.46      0.06      0.10       102\n",
      "          36       0.63      0.27      0.38        90\n",
      "          37       0.17      0.04      0.07        23\n",
      "          38       0.63      0.41      0.50       136\n",
      "          39       0.18      0.13      0.15        45\n",
      "          40       0.64      0.40      0.49       243\n",
      "          41       0.45      0.27      0.33        49\n",
      "          42       0.60      0.35      0.44       113\n",
      "          43       0.48      0.32      0.38       133\n",
      "          44       0.24      0.18      0.20       118\n",
      "          45       0.20      0.13      0.16        31\n",
      "          46       0.41      0.17      0.24       105\n",
      "          47       0.29      0.07      0.11        29\n",
      "          48       0.50      0.24      0.33        29\n",
      "          49       0.42      0.21      0.28        68\n",
      "          50       0.20      0.04      0.07        47\n",
      "          51       0.10      0.05      0.06        22\n",
      "          52       0.56      0.25      0.35        36\n",
      "          53       0.48      0.45      0.46        29\n",
      "          54       0.75      0.39      0.51       116\n",
      "          55       0.75      0.62      0.68        99\n",
      "          56       0.53      0.35      0.42        46\n",
      "          57       0.56      0.58      0.57        38\n",
      "          58       0.71      0.57      0.63        53\n",
      "          59       0.23      0.07      0.11       160\n",
      "\n",
      "   micro avg       0.52      0.28      0.37      3991\n",
      "   macro avg       0.45      0.26      0.32      3991\n",
      "weighted avg       0.48      0.28      0.34      3991\n",
      " samples avg       0.30      0.29      0.28      3991\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Metrics for TF-IDF with 1-2 n-grams:')\n",
    "print(classification_report(y_val, n_gram_tf_idf_y_pred_val, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate `recall@k`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean recall@k for k=5 for TF-IDF with 1-2 n-grams: 0.291\n"
     ]
    }
   ],
   "source": [
    "n_gram_tf_idf_recallk_mean, n_gram_tf_idf_recallk_med = recallk(n_gram_tf_idf_df_val.tags, n_gram_tf_idf_df_val.predicted_tags, k=K)\n",
    "\n",
    "print(f'Mean recall@k for k={K} for TF-IDF with 1-2 n-grams: {n_gram_tf_idf_recallk_mean:.3f}')\n",
    "#print(f'Median recall@k for k={K} for TF-IDF with 1-2 n-grams: {n_gram_tf_idf_recallk_med:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4. Training on rubert-tiny-v2 embeddings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_paths = module_path + '/data/embeddings/rubert-tiny-v2/'\n",
    "\n",
    "emb_pth = [emb_paths + 'texts.parquet']\n",
    "emb = merge_dataset(emb_pth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2936217</td>\n",
       "      <td>[0.3411005, -0.16877297, -0.3599054, 0.011505239, -0.19693527, 0.16206133, -0.62560713, -0.38459125, -0.08364315, -0.17384137, -0.2905479, 0.8844394, -0.07451144, 1.9678769, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6991412</td>\n",
       "      <td>[0.3696494, 0.06409113, -0.62138826, -0.8906186, 0.08984075, 0.27482352, -0.31647494, -0.778525, -0.6068895, 0.42193377, -0.05778958, 0.017193496, 0.14765958, 0.35776424, -0.16...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  \\\n",
       "0  2936217   \n",
       "1  6991412   \n",
       "\n",
       "                                                                                                                                                                             embedding  \n",
       "0  [0.3411005, -0.16877297, -0.3599054, 0.011505239, -0.19693527, 0.16206133, -0.62560713, -0.38459125, -0.08364315, -0.17384137, -0.2905479, 0.8844394, -0.07451144, 1.9678769, 0....  \n",
       "1  [0.3696494, 0.06409113, -0.62138826, -0.8906186, 0.08984075, 0.27482352, -0.31647494, -0.778525, -0.6068895, 0.42193377, -0.05778958, 0.017193496, 0.14765958, 0.35776424, -0.16...  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb = emb[emb['id'].isin(data['id'])]\n",
    "\n",
    "emb_train = emb[emb['id'].isin(data_train['id'])]\n",
    "emb_val = emb[emb['id'].isin(data_val['id'])]\n",
    "emb_test = emb[emb['id'].isin(data_test['id'])]\n",
    "\n",
    "assert len(emb_train) == len(data_train), \"Something went wrong!\"\n",
    "assert len(emb_val) == len(data_val), \"Something went wrong!\"\n",
    "assert len(emb_test) == len(data_test), \"Something went wrong!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_emb = [i for i in emb_train.embedding]\n",
    "X_val_emb = [i for i in emb_val.embedding]\n",
    "X_test_emb = [i for i in emb_test.embedding]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X embeddings shapes:\n",
      "   • X train shape: (25209, 312)\n",
      "   • X val shape: (2821, 312)\n",
      "   • X test shape: (3119, 312)\n"
     ]
    }
   ],
   "source": [
    "print(\"X embeddings shapes:\")\n",
    "print(f'   • X train shape: {np.shape(X_train_emb)}')\n",
    "print(f'   • X val shape: {np.shape(X_val_emb)}')\n",
    "print(f'   • X test shape: {np.shape(X_test_emb)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "LogReg_cfg = {'C':1e8,\n",
    "              'penalty': 'l2',\n",
    "              'dual': False,\n",
    "              'class_weight': tag_distr_formated,\n",
    "              'solver': 'lbfgs',\n",
    "              'random_state': 42}\n",
    "\n",
    "clf_ovr = OneVsRestClassifier(estimator=LogisticRegression(C=LogReg_cfg['C'],\n",
    "                                                           dual=LogReg_cfg['dual'],\n",
    "                                                           class_weight=LogReg_cfg['class_weight'],\n",
    "                                                           penalty=LogReg_cfg['penalty'],\n",
    "                                                           solver=LogReg_cfg['solver'],\n",
    "                                                           random_state=LogReg_cfg['random_state']),\n",
    "                              n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isfile(save_models_path + 'rubert.joblib'):\n",
    "    clf_ovr = load(save_models_path + 'rubert.joblib')\n",
    "else:\n",
    "    clf_ovr.fit(X_train_emb, y_train)\n",
    "    dump(clf_ovr, save_models_path + 'rubert.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "rubert_y_pred_val = clf_ovr.predict(X_val_emb)\n",
    "rubert_y_probas = clf_ovr.predict_proba(X_val_emb)\n",
    "rubert_y_labels = sorted_labels(rubert_y_pred_val, rubert_y_probas, Vec)\n",
    "\n",
    "rubert_df_val = data_val.copy()\n",
    "rubert_df_val['predicted_tags'] = rubert_y_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text_markdown</th>\n",
       "      <th>tags</th>\n",
       "      <th>predicted_tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>421</th>\n",
       "      <td>6992880</td>\n",
       "      <td>[популярный, пк, игра, создавать, устройство, проходить, картинка, память, оставаться, различный, создавать, написать, догадка, дикий, желание, проходить]</td>\n",
       "      <td>[помогите найти]</td>\n",
       "      <td>[игры, помогите найти, поиск]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432</th>\n",
       "      <td>6992917</td>\n",
       "      <td>[профессия, оказываться, сопровождать, образование, курсы, обязанность, входить, хотеться, разговор, зажигать, свеча, оказываться, нарушение, род, кодекс, общий, тысяча, цена, ...</td>\n",
       "      <td>[психология]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>578</th>\n",
       "      <td>6994231</td>\n",
       "      <td>[предыдущий, пост, бригада, график, переписывать, месяц, дата, окончание, поездка, графика, случаться, называть, двойной, поездка, бригада, происходить, ошибка, редко, ситуация...</td>\n",
       "      <td>[юмор, реальная история из жизни]</td>\n",
       "      <td>[работа]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>591</th>\n",
       "      <td>6992488</td>\n",
       "      <td>[широкий, хотеться, обращать, внимание, инцидент, связанный, дтп, участие, пожарный, двигаться, оперативный, вызов, включать, сигнал, легко, заводить, уголовный, водитель, факт...</td>\n",
       "      <td>[помощь]</td>\n",
       "      <td>[помощь]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>807</th>\n",
       "      <td>7021892</td>\n",
       "      <td>[история, скоро, девушка, упасть, дерево, парень, неловко, улыбаться, следовать, забывать, следить, окружение, темно, отзываться, слегка, восклицать, показывать, парень, старат...</td>\n",
       "      <td>[рассказ, фантастика, мат]</td>\n",
       "      <td>[авторский рассказ, рассказ, фантастика]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22025</th>\n",
       "      <td>6427557</td>\n",
       "      <td>[принцесса, сообщать, рыцарь, высовываться, башня, брать, удивляться, дракон, башня, рыцарь, пожимать, башня, заводиться, крыса, рассказывать, бояться, башня, крыса, кот, принц...</td>\n",
       "      <td>[история, рассказ]</td>\n",
       "      <td>[анекдот, фантастика, рассказ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22285</th>\n",
       "      <td>1144000</td>\n",
       "      <td>[узнавать, заболевание, бегать, проводить, офис, отказывать, общение, близкий, польза, совещание, начальство, скрывать, чувство, любимый, тратить, ненужный, интересно, вести, э...</td>\n",
       "      <td>[жизнь]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22317</th>\n",
       "      <td>3356103</td>\n",
       "      <td>[просматривать, карта, местность, цель, дальнейший, определение, установка, мудрый, иван, ипать, рассматривать, карта, просить, помощник, подавать, ипать, саша, подавать, бухга...</td>\n",
       "      <td>[история]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22859</th>\n",
       "      <td>6969784</td>\n",
       "      <td>[связь, срочный, поиск, посещать, агентство, находиться, столичный, предлагать, непонятно, рубль, московский, цена, основное, ближний, исключение, брат, находиться, рф, стадия,...</td>\n",
       "      <td>[москва, работа]</td>\n",
       "      <td>[москва]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22980</th>\n",
       "      <td>6858324</td>\n",
       "      <td>[детство, играть, игра, начальный, персонаж, приезжать, поезд, подземный, лаборатория, ходить, всякий, передвигаться, лифт, момент, происходить, лифт, ломаться, освещение, неко...</td>\n",
       "      <td>[игры]</td>\n",
       "      <td>[ищу книгу, помогите найти, фантастика]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2821 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id  \\\n",
       "421    6992880   \n",
       "432    6992917   \n",
       "578    6994231   \n",
       "591    6992488   \n",
       "807    7021892   \n",
       "...        ...   \n",
       "22025  6427557   \n",
       "22285  1144000   \n",
       "22317  3356103   \n",
       "22859  6969784   \n",
       "22980  6858324   \n",
       "\n",
       "                                                                                                                                                                             text_markdown  \\\n",
       "421                             [популярный, пк, игра, создавать, устройство, проходить, картинка, память, оставаться, различный, создавать, написать, догадка, дикий, желание, проходить]   \n",
       "432    [профессия, оказываться, сопровождать, образование, курсы, обязанность, входить, хотеться, разговор, зажигать, свеча, оказываться, нарушение, род, кодекс, общий, тысяча, цена, ...   \n",
       "578    [предыдущий, пост, бригада, график, переписывать, месяц, дата, окончание, поездка, графика, случаться, называть, двойной, поездка, бригада, происходить, ошибка, редко, ситуация...   \n",
       "591    [широкий, хотеться, обращать, внимание, инцидент, связанный, дтп, участие, пожарный, двигаться, оперативный, вызов, включать, сигнал, легко, заводить, уголовный, водитель, факт...   \n",
       "807    [история, скоро, девушка, упасть, дерево, парень, неловко, улыбаться, следовать, забывать, следить, окружение, темно, отзываться, слегка, восклицать, показывать, парень, старат...   \n",
       "...                                                                                                                                                                                    ...   \n",
       "22025  [принцесса, сообщать, рыцарь, высовываться, башня, брать, удивляться, дракон, башня, рыцарь, пожимать, башня, заводиться, крыса, рассказывать, бояться, башня, крыса, кот, принц...   \n",
       "22285  [узнавать, заболевание, бегать, проводить, офис, отказывать, общение, близкий, польза, совещание, начальство, скрывать, чувство, любимый, тратить, ненужный, интересно, вести, э...   \n",
       "22317  [просматривать, карта, местность, цель, дальнейший, определение, установка, мудрый, иван, ипать, рассматривать, карта, просить, помощник, подавать, ипать, саша, подавать, бухга...   \n",
       "22859  [связь, срочный, поиск, посещать, агентство, находиться, столичный, предлагать, непонятно, рубль, московский, цена, основное, ближний, исключение, брат, находиться, рф, стадия,...   \n",
       "22980  [детство, играть, игра, начальный, персонаж, приезжать, поезд, подземный, лаборатория, ходить, всякий, передвигаться, лифт, момент, происходить, лифт, ломаться, освещение, неко...   \n",
       "\n",
       "                                    tags  \\\n",
       "421                     [помогите найти]   \n",
       "432                         [психология]   \n",
       "578    [юмор, реальная история из жизни]   \n",
       "591                             [помощь]   \n",
       "807           [рассказ, фантастика, мат]   \n",
       "...                                  ...   \n",
       "22025                 [история, рассказ]   \n",
       "22285                            [жизнь]   \n",
       "22317                          [история]   \n",
       "22859                   [москва, работа]   \n",
       "22980                             [игры]   \n",
       "\n",
       "                                 predicted_tags  \n",
       "421               [игры, помогите найти, поиск]  \n",
       "432                                          []  \n",
       "578                                    [работа]  \n",
       "591                                    [помощь]  \n",
       "807    [авторский рассказ, рассказ, фантастика]  \n",
       "...                                         ...  \n",
       "22025            [анекдот, фантастика, рассказ]  \n",
       "22285                                        []  \n",
       "22317                                        []  \n",
       "22859                                  [москва]  \n",
       "22980   [ищу книгу, помогите найти, фантастика]  \n",
       "\n",
       "[2821 rows x 4 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rubert_df_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for rubert embeddings:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      0.32      0.31        25\n",
      "           1       0.39      0.31      0.35        45\n",
      "           2       0.58      0.17      0.27        40\n",
      "           3       0.47      0.33      0.39        27\n",
      "           4       0.35      0.30      0.32        27\n",
      "           5       0.16      0.04      0.07        68\n",
      "           6       0.29      0.15      0.20        40\n",
      "           7       0.36      0.20      0.26        59\n",
      "           8       0.35      0.17      0.23        42\n",
      "           9       0.42      0.34      0.37       113\n",
      "          10       0.30      0.22      0.25        50\n",
      "          11       0.10      0.01      0.02        85\n",
      "          12       0.25      0.01      0.03        72\n",
      "          13       0.63      0.59      0.61        58\n",
      "          14       0.00      0.00      0.00        52\n",
      "          15       0.00      0.00      0.00        28\n",
      "          16       0.25      0.03      0.05       135\n",
      "          17       0.58      0.61      0.60        23\n",
      "          18       0.55      0.64      0.59        25\n",
      "          19       0.28      0.20      0.23        50\n",
      "          20       0.24      0.21      0.22        29\n",
      "          21       0.69      0.64      0.66       164\n",
      "          22       0.72      0.51      0.60        45\n",
      "          23       0.32      0.09      0.14        77\n",
      "          24       0.46      0.34      0.39        32\n",
      "          25       0.25      0.13      0.17        47\n",
      "          26       0.00      0.00      0.00        25\n",
      "          27       0.49      0.24      0.32       218\n",
      "          28       0.30      0.27      0.28        48\n",
      "          29       0.42      0.13      0.20        39\n",
      "          30       0.49      0.47      0.48        38\n",
      "          31       0.12      0.03      0.04        38\n",
      "          32       0.60      0.11      0.19        53\n",
      "          33       0.37      0.30      0.33        57\n",
      "          34       0.55      0.40      0.46        57\n",
      "          35       0.08      0.01      0.02       102\n",
      "          36       0.61      0.22      0.33        90\n",
      "          37       0.04      0.04      0.04        23\n",
      "          38       0.64      0.43      0.51       136\n",
      "          39       0.27      0.29      0.28        45\n",
      "          40       0.57      0.42      0.48       243\n",
      "          41       0.42      0.27      0.33        49\n",
      "          42       0.56      0.39      0.46       113\n",
      "          43       0.47      0.27      0.34       133\n",
      "          44       0.27      0.08      0.12       118\n",
      "          45       0.12      0.06      0.08        31\n",
      "          46       0.39      0.21      0.27       105\n",
      "          47       0.36      0.14      0.20        29\n",
      "          48       0.17      0.07      0.10        29\n",
      "          49       0.33      0.16      0.22        68\n",
      "          50       0.17      0.02      0.04        47\n",
      "          51       0.12      0.05      0.07        22\n",
      "          52       0.36      0.22      0.28        36\n",
      "          53       0.38      0.31      0.34        29\n",
      "          54       0.72      0.72      0.72       116\n",
      "          55       0.75      0.60      0.66        99\n",
      "          56       0.50      0.41      0.45        46\n",
      "          57       0.46      0.42      0.44        38\n",
      "          58       0.53      0.47      0.50        53\n",
      "          59       0.27      0.04      0.07       160\n",
      "\n",
      "   micro avg       0.48      0.27      0.34      3991\n",
      "   macro avg       0.37      0.25      0.28      3991\n",
      "weighted avg       0.41      0.27      0.31      3991\n",
      " samples avg       0.28      0.28      0.26      3991\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Metrics for rubert embeddings:')\n",
    "print(classification_report(y_val, rubert_y_pred_val, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate `recall@k`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean recall@k for k=5 for model with rubert embeddings: 0.275\n"
     ]
    }
   ],
   "source": [
    "rubert_recallk_mean, rubert_recallk_med = recallk(rubert_df_val.tags, rubert_df_val.predicted_tags, k=K)\n",
    "\n",
    "print(f'Mean recall@k for k={K} for model with rubert embeddings: {rubert_recallk_mean:.3f}')\n",
    "#print(f'Median recall@k for k={K} for model with rubert embeddings:: {rubert_recallk_med:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 3. Results\n",
    "\n",
    "As the result of training with different embeddings, we have the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean recall@k's for LogReg with k = 5:\n",
      "\n",
      "  • Recall@k for Bag-of-Words: 0.3041\n",
      "  • Recall@k for TF-IDF: 0.2968\n",
      "  • Recall@k for TF-IDF with uni- and bi- grams: 0.2909\n",
      "  • Recall@k for rubert embeddings: 0.2750\n"
     ]
    }
   ],
   "source": [
    "print(f\"Mean recall@k's for LogReg with k = {K}:\\n\")\n",
    "print(f'  • Recall@k for Bag-of-Words: {bow_recallk_mean:.4f}')\n",
    "print(f'  • Recall@k for TF-IDF: {tf_idf_recallk_mean:.4f}')\n",
    "print(f'  • Recall@k for TF-IDF with uni- and bi- grams: {n_gram_tf_idf_recallk_mean:.4f}')\n",
    "print(f'  • Recall@k for rubert embeddings: {rubert_recallk_mean:.4f}')\n",
    "\n",
    "#print(f\"\\nMedian recall@k's for LogReg with k = {K}:\\n\")\n",
    "#print(f'  • Recall@k for Bag-of-Words: {bow_recallk_med:3f}')\n",
    "#print(f'  • Recall@k for TF-IDF: {tf_idf_recallk_med:3f}')\n",
    "#print(f'  • Recall@k for TF-IDF with uni- and bi- grams: {n_gram_tf_idf_recallk_med:3f}')\n",
    "#print(f'  • Recall@k for rubert embeddings: {rubert_recallk_med:3f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
